<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>hw4</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,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);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                messageStyle: 'none',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      maxEdges: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        let { svg } = await mermaid.render(id, raw, el);
        svg = cleanMermaidSvg(svg);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }


    /**
     * Post-process to ensure mermaid diagrams contain only valid SVG and XHTML.
     */
    function cleanMermaidSvg(svg) {
      return svg.replace(RE_VOID_ELEMENT, replaceVoidElement);
    }


    /**
     * A regular expression for all void elements, which may include attributes and
     * a slash.
     *
     * @see https://developer.mozilla.org/en-US/docs/Glossary/Void_element
     *
     * Of these, only `<br>` is generated by Mermaid in place of `\n`,
     * but _any_ "malformed" tag will break the SVG rendering entirely.
     */
    const RE_VOID_ELEMENT =
      /<\s*(area|base|br|col|embed|hr|img|input|link|meta|param|source|track|wbr)\s*([^>]*?)\s*>/gi;

    /**
     * Ensure a void element is closed with a slash, preserving any attributes.
     */
    function replaceVoidElement(match, tag, rest) {
      rest = rest.trim();
      if (!rest.endsWith('/')) {
        rest = `${rest} /`;
      }
      return `<${tag} ${rest}>`;
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="HW4:-Large-Language-Models">HW4: Large Language Models<a class="anchor-link" href="#HW4:-Large-Language-Models"></a></h1><p>In this assignment, you will be implementing language models for next token prediction and generation of Shakespeare! This assignment will be in two parts. <strong>For this final assignment, you have the option to work in pairs.</strong></p>
<p><strong>Part 1:</strong></p>
<p>In this part, you will review some key ingredients of sequence modeling. In the process, you will build a baseline transformer model for next token prediction trained on Shakespeare's works. We have provided the scaffolding for the code in this part of the assignment, and your task will be to fill in the key implementation steps.</p>
<p><strong>Part 2:</strong></p>
<p>This part is an open-ended mini-project where you have the freedom to try sequence modeling approaches of your choice on this problem. You should feel free to try other architectures (HMMs, RNNs, transformers, state space layers, diffusion models etc.) or to invent new architectures. You may also experiment with new algorithms for fitting or training these models. The goal will be to find some area of possible improvement (we interpret "improvement" quite loosely, but it is up to you to state precisely why your proposed innovation might constitute an improvement and to show convincing evidence that your innovation does or does not); to formulate and state a precise hypothesis; and to falsify or support the hypothesis with rigorous empirical analyses.</p>
<p><strong>Deliverables:</strong></p>
<ul>
<li>Code for Parts 1 of the assignment</li>
<li>A written report of at most 4 pages for Part 2 (references not included in the page limit), with a link to code for Part 2.</li>
</ul>
<p><em>Note: the code for Part 2 will not be graded, but we ask you to include a link to it for completeness.</em></p>
<p><strong>Important: Choosing runtimes</strong></p>
<p>Google Colab has limits on the free usage of GPU runtimes. For this assignment, <strong>we strongly recommend doing the majority of your prototyping, testing, and small-scale experiments on CPU backend</strong>. Then, once you are ready to train your models, you should switch to a T4 GPU.</p>
<p>You can change runtime type by clicking <strong>Runtime -&gt; Change Runtime Type</strong> in the tabs above. You can monitor your resource usages in the top right corner of the screen (it should say what backend you are using, how many compute units per hour you are using, etc.)</p>
<p><strong>Make sure to turn off GPU runtime if you are not actively using it!</strong></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Setup">Setup<a class="anchor-link" href="#Setup"></a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># torch imports</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">305</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">'mps'</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>We set default values for some global hyperparameters, but feel free to change these during development as needed.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Global hyperparameters</span>
<span class="n">SMALL_ITERS</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">LARGE_ITERS</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">EVAL_ITERS</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">CONTEXT_WINDOW_SIZE</span> <span class="o">=</span> <span class="mi">256</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Part-0:-Preprocessing">Part 0: Preprocessing<a class="anchor-link" href="#Part-0:-Preprocessing"></a></h2><p>As in the previous problem sets, a certain amount of preprocessing for textual data is required.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="0.1:-Loading-and-preprocessing-the-dataset">0.1: Loading and preprocessing the dataset<a class="anchor-link" href="#0.1:-Loading-and-preprocessing-the-dataset"></a></h3><p>The first step is to download the dataset. We will be using a dataset from Andrej Karpathy consisting of a subset of works from Shakespeare.</p>
<p>The dominant mode for preprocessing textual data is to tokenize it; that is, to split the dataset into a finite vocabulary of tokens. Then, we can set up a dictionaries mapping from counting numbers (representing tokens) to tokens and vice versa. Tokens can be characters, or words, or subwords; in fact, the "best" way to tokenize text is an active area of research.</p>
<p>To keep things simple, we'll tokenize the text on a per-character level.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># download the tiny shakespeare dataset</span>
<span class="n">input_file_path</span> <span class="o">=</span> <span class="s1">'input.txt'</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">input_file_path</span><span class="p">):</span>
    <span class="n">data_url</span> <span class="o">=</span> <span class="s1">'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">input_file_path</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">data_url</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">input_file_path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"length of dataset in characters: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>length of dataset in characters: 1,115,394
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># get all the unique characters that occur in this text</span>
<span class="n">chars</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"all the unique characters:"</span><span class="p">,</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">chars</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"vocab size: </span><span class="si">{</span><span class="n">vocab_size</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>all the unique characters: 
 !$&amp;',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz
vocab size: 65
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># create a mapping from characters to integers</span>
<span class="n">stoi</span> <span class="o">=</span> <span class="p">{</span> <span class="n">ch</span><span class="p">:</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">ch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span> <span class="p">}</span>
<span class="n">itos</span> <span class="o">=</span> <span class="p">{</span> <span class="n">i</span><span class="p">:</span><span class="n">ch</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">ch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span> <span class="p">}</span>

<span class="k">def</span><span class="w"> </span><span class="nf">encode</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">stoi</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">s</span><span class="p">]</span> <span class="c1"># encoder: take a string, output a list of integers</span>
<span class="k">def</span><span class="w"> </span><span class="nf">decode</span><span class="p">(</span><span class="n">l</span><span class="p">):</span>
    <span class="k">return</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">itos</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">l</span><span class="p">])</span> <span class="c1"># decoder: take a list of integers, output a string</span>

<span class="c1"># create the train and test splits</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">train_chars</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="mf">0.9</span><span class="p">)]</span>
<span class="n">val_chars</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="mf">0.9</span><span class="p">):]</span>

<span class="c1"># encode both to integers</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">encode</span><span class="p">(</span><span class="n">train_chars</span><span class="p">)</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">encode</span><span class="p">(</span><span class="n">val_chars</span><span class="p">)</span>

<span class="c1"># cast as torch tensors</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">val_data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"train has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> tokens"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"val has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">val_data</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> tokens"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>train has 1,003,854 tokens
val has 111,540 tokens
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>We also write helper functions to get batches of data and to evaluate the loss of various models on them.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># function for getting batches of data</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_batch</span><span class="p">(</span><span class="n">split</span><span class="p">,</span> <span class="n">context_window_size</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    generate a small batch of data of inputs x and targets y</span>

<span class="sd">    Args:</span>
<span class="sd">        split: 'train' or 'val'</span>
<span class="sd">        device: 'cpu' or 'cuda' (should be 'cuda' if available)</span>
<span class="sd">    """</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">train_data</span> <span class="k">if</span> <span class="n">split</span> <span class="o">==</span> <span class="s1">'train'</span> <span class="k">else</span> <span class="n">val_data</span>
    <span class="n">ix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="n">context_window_size</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">context_window_size</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ix</span><span class="p">])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">context_window_size</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ix</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>

<span class="c1"># helper function for tracking loss during training</span>
<span class="c1"># given to you</span>
<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">estimate_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">eval_iters</span><span class="p">,</span> <span class="n">context_window_size</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Args:</span>
<span class="sd">      model: model being evaluated</span>
<span class="sd">      eval_iters: number of batches to average over</span>
<span class="sd">      context_window_size: size of the context window</span>
<span class="sd">      device: 'cpu' or 'cuda' (should be 'cuda' if available)</span>
<span class="sd">    """</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'train'</span><span class="p">,</span> <span class="s1">'val'</span><span class="p">]:</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">eval_iters</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">eval_iters</span><span class="p">):</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">split</span><span class="p">,</span> <span class="n">context_window_size</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
            <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
            <span class="n">losses</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">out</span><span class="p">[</span><span class="n">split</span><span class="p">]</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Part-1:-Language-Modeling">Part 1: Language Modeling<a class="anchor-link" href="#Part-1:-Language-Modeling"></a></h2><p>In this first part of the assignment, we will implement a baseline for code modeling.</p>
<p>In the process of building this baseline, we will review 4 key ideas of sequence modeling that have become the backbone of modern language models such as ChatGPT:</p>
<ol>
<li>Framing language modeling as next token prediction, and next token prediction as multiclass logistic regression</li>
<li>Embedding discrete tokens in continuous latent spaces (word embeddings)</li>
<li>Use the attention mechanism to move beyond Markovian models for sequences (we of course pay for this greater expressivity with increased compute, which is made possible in part by using matrix multiplications on hardware accelerators like GPUs. Reducing the compute burden while maintaining the expressivity needed for good sequence modeling is an active area of research).</li>
<li>Combining attention with deep learning in the Transformer architecture.</li>
</ol>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="1.1:-Next-token-prediction-as-multiclass-logistic-regression">1.1: Next token prediction as multiclass logistic regression<a class="anchor-link" href="#1.1:-Next-token-prediction-as-multiclass-logistic-regression"></a></h3><p>Our first language model will simply be a lookup table. That is, given that we have token with value $v$, we will simply "look up" the logits that correspond to our prediction for the next token. This model is often known as a "bigram model" because it can be derived from the relative proportions of different bigrams (ordered pairs of tokens) occurring in a large text corpus.</p>
<p>Let us be a bit more precise in our definition of the bigram model. Let's say that the total size of our vocabulary (the number of tokens we are using) is $V$. Let $A$ be a matrix in $\mathbb{R}^{V \times V}$, where each row $A_v$ corresponds to the logits for the prediction of which token would follow a token that has value $v$.
Thus, we are modeling the distribution of the token following a token that has value $v$ as
\begin{align*}
y_{t+1} \mid y_t &amp;= v \sim \mathrm{Cat}(\mathbf{\pi}) \\
\pi &amp;=\mathrm{softmax}(A_v)
\end{align*}</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Question-1.1.1">Question 1.1.1<a class="anchor-link" href="#Question-1.1.1"></a></h4><p>$\mathbf{\pi} \in \Delta_{V-1}$ is the vector of probabilities used to parameterize the categorical distribution for the next token prediction. Explain why we parameterize
\begin{equation*}
  \mathbf{\pi} = \mathrm{softmax}(A_v),
\end{equation*}
and could not just use
\begin{equation*}
  \mathbf{\pi} = A_v.
\end{equation*}</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
<p>Because we want the probabilities of picking each class which the softmax function gives us.</p>
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Question-1.1.2">Question 1.1.2<a class="anchor-link" href="#Question-1.1.2"></a></h4><p>Discuss the relationship between the bigram model and contigency tables (discussed in Lecture 1).</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
<p>The bigram model is related to the contingency tables discussed in Lecture 1 because the model forms a V x V table where each row corresponds to the transition probabilities from a given token to each of the other tokens. As these are conditional probabilities, we can multiply each entry by the sum of the entries in corresponding row (marginal probability) to get the joint probability.</p>
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Question-1.1.3">Question 1.1.3<a class="anchor-link" href="#Question-1.1.3"></a></h4><p>Say I have a string of three tokens with ids $(7, 3, 6)$. If I use the bigram model as a generative model for language, given this information, what is distribution of the fourth token? Write your answer in terms of the matrix $A$ we defined in 1.1</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
<p>Assuming there are $V$ possible tokens, we can write the distribution of the next token as the conditional distribution given the most recent token, 6 (Markov Property).</p>
<p>Define each entry $A_{ij}$ as the logit for the prediction from token $i$ to token $j$. Therefore,</p>
<p>\begin{align*}
\pi &amp;= \frac{1}{\sum_{j=1}^V \exp(A_{6j})} \bigg(\exp(A_{61}), \exp(A_{62}), \ldots, \exp(A_{6V}) \bigg) \\
\end{align*}</p>
<p>Where each entry in $\pi$ is represents the probability of choosing token $j$ from token 6. Thus, the distribution of the fourth token is a categorical distribution where each probability is given by the respective entry in $\pi$.</p>
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Question-1.1.4">Question 1.1.4<a class="anchor-link" href="#Question-1.1.4"></a></h4><p>Remember back in Part 0 when we gave you the helper function <code>get_batch</code>? Run <code>get_batch</code> and look at the inputs <code>x</code> and the targets <code>y</code>. Explain any relation between them in the context of formulating language modeling in the context of next token prediction.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s1">'train'</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"the features have token ids </span><span class="si">{</span><span class="n">xb</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"the targets have token ids </span><span class="si">{</span><span class="n">yb</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>the features have token ids tensor([[47, 53, 59, 57,  1, 50, 53, 60, 43,  6]], device='mps:0')


the targets have token ids tensor([[53, 59, 57,  1, 50, 53, 60, 43,  6,  0]], device='mps:0')
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
<p>The features are one token behind the targets, as the features will be used to train the models based on the values of the targets. In other words, the target tokens are the same sequence as the features tokens but shifted one token to the right. This is important in the context of formulating language modeling because the model will learn to predict the next token (target) based on the current token (feature).</p>
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Question-1.1.5">Question 1.1.5<a class="anchor-link" href="#Question-1.1.5"></a></h4><p>Discuss the strengths and weaknesses of the bigram model as a generative model for language.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
<p>Strengths:</p>
<p>The bigram model is computationally inexpensive, easy to understand, and works well on small sequences to capture shorter dependencies between words.</p>
<p>Weaknesses:</p>
<p>The model's predictions are only based on the last token, which may not be relevant for language modeling since certain words and linguistic structures are based upon more than just one previous token. Furthermore, it is susceptible to data sparsity as the vocabulary increases, leading to potential computational challenges as the number of bigram pairs increases. Finally, the bigram model suffers with out-of-vocabulary words that are not used in training.</p>
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Question-1.1.6">Question 1.1.6<a class="anchor-link" href="#Question-1.1.6"></a></h4><p>Say I have a string $s$ of length $T$. Derive the formula for the negative log likelihood of $s$ under the bigram model in terms of the matrix of logits $A$. What would your answer be if the matrix of logits $A$ were all zeros? What would be the value of the negative log likelihood of $s$ under a model that always perfectly predicted the next token?</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
<p>Begin with the definition of the likelihood of $s$:</p>
<p>\begin{align*}
P(s) &amp;= \prod_{t=t}^T P(S_t | S_{t-1}) \\
\end{align*}</p>
<p>Where:</p>
<p>\begin{align*}
P(S_t | S_{t-1}) &amp;= \frac{\exp(A_{S_{t-1},S_t})}{\sum_{j=1}^{V} \exp(A_{S_{t-1},j})} \\
\end{align*}</p>
<p>Thus:</p>
<p>\begin{align*}
P(s) &amp;= \prod_{t=2}^T \frac{\exp(A_{S_{t-1},S_t})}{\sum_{j=1}^{V} \exp(A_{S_{t-1},j})} \\
\end{align*}</p>
<p>However, since we are aiming for the negative log likelihood, we want:</p>
<p>\begin{align*}
\log{P(s)} &amp;= \sum_{t=2}^T \log{\frac{\exp(A_{S_{t-1},S_t})}{\sum_{j=1}^{V} \exp(A_{S_{t-1},j})}} \\
\log{P(s)} &amp;= \sum_{t=2}^T \bigg( A_{S_{t-1},S_t} - \log{\sum_{j=1}^{V} \exp(A_{S_{t-1},j})} \bigg) \\
\end{align*}</p>
<p>Finally:</p>
<p>\begin{align*}
- \log{P(s)} &amp;= - \sum_{t=2}^T \bigg( A_{S_{t-1},S_t} - \log{\sum_{j=1}^{V} \exp(A_{S_{t-1},j})} \bigg) \\
\end{align*}</p>
<p>If the matrix of logits is all 0s, we would expect every A term in the above formula to be 0, and thus:</p>
<p>\begin{align*}
-\log{P(s)} &amp;= -\sum_{t=2}^T \bigg( 0- \log{\sum_{j=1}^{V} \exp(0)} \bigg) \\
-\log{P(s)} &amp;= -\sum_{t=2}^T \bigg( 0- \log{\sum_{j=1}^{V} 1} \bigg) \\
-\log{P(s)} &amp;= -\sum_{t=2}^T \bigg(-\log{V} \bigg) \\
-\log{P(s)} &amp;= (T-1)\log{V} \\
\end{align*}</p>
<p>Thus, if the logits are all 0, then the negative log likelihood is proportional to the length of the sequence and the log of the vocabulary.</p>
<p>However, if all predictions are perfect, then we know that the value of $A_{S_{t-1},S_t}$ must be significantly larger than all $A_{S_{t-1},j}$ for $j \in [1,V]$. Thus, we surmise $\sum_{j=1}^{V} \exp(A_{S_{t-1},j}) \approx \exp(A_{S_{t-1},S_t})$. Using this result, we get:</p>
<p>\begin{align*}
- \log{P(s)} &amp;= - \sum_{t=2}^T \bigg( A_{S_{t-1},S_t} - \log{\exp(A_{S_{t-1},S_t})} \bigg) \\
- \log{P(s)} &amp;= - \sum_{t=2}^T \bigg( A_{S_{t-1},S_t} - A_{S_{t-1},S_t} \bigg) \\
- \log{P(s)} &amp;= 0 \\
\end{align*}</p>
<p>Implying that the negative log likelihood is 0 when the model perfectly predicts the next token.</p>
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Question-1.1.7:-Implement-the-BigramLanguageModel">Question 1.1.7: Implement the BigramLanguageModel<a class="anchor-link" href="#Question-1.1.7:-Implement-the-BigramLanguageModel"></a></h4><p>Implement the bigram language model below.</p>
<p>Your TODOs:</p>
<ul>
<li>if the <code>forward</code> method is provided a target, the loss should be the negative log likelihood of the target (given the context)</li>
<li><code>generate</code> should take in (batched) contexts and a number of new tokens to generate, and then generate text autoregressively from your model. Note that in autoregressive text generation, you iteratively append the tokens you generate to your context.</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">BigramLanguageModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">          vocab_size: size of the vocabulary (the number of tokens)</span>
<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># each token directly reads off the logits for the next token from a lookup table</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logits_table</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">          token_ids: Int(B, T), token ids that make up the context (batch has size B, each entry in the batch has length T)</span>
<span class="sd">          targets: Int(B, T), token ids corresponding to the target of each context in token_ids</span>

<span class="sd">        Returns:</span>
<span class="sd">          logits: (B, T, V), logits[b,t, :] gives the length V vector of logits for the next token prediction in string b up to t tokens</span>
<span class="sd">          loss: scalar, negative log likelihood of target given context</span>
<span class="sd">        """</span>

        <span class="c1"># idx and targets are both (B,T) tensor of integers</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logits_table</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span> <span class="c1"># (B,T,V)</span>

        <span class="k">if</span> <span class="n">targets</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># TODO: what should the loss in this setting be?</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">targets</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">          token_ids: (B, T) tensor of token ids to provide as context</span>
<span class="sd">          max_new_tokens: int, maximum number of new tokens to generate</span>

<span class="sd">        Returns:</span>
<span class="sd">          (B, T+max_new_tokens) tensor of context with new tokens appended</span>
<span class="sd">        """</span>
        <span class="c1"># TODO: your code below</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">new_token_ids</span> <span class="o">=</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">):</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logits_table</span><span class="p">(</span><span class="n">new_token_ids</span><span class="p">)</span>
            <span class="n">new_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">new_token_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">new_token_ids</span><span class="p">,</span> <span class="n">new_token</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_token_ids</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Question-1.1.8:-Evaluating-the-initialization.">Question 1.1.8: Evaluating the initialization.<a class="anchor-link" href="#Question-1.1.8:-Evaluating-the-initialization."></a></h4><p>Evaluate the loss of your untrained bigram model on a batch of data. Make sure the loss (negative log likelihood) is per-token (i.e. you may need to average over both sequence length and batch). Does this loss make sense in the context of your answer to Question 1.1.6? Discuss.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s2">"train"</span><span class="p">,</span> <span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="n">bigram_model</span> <span class="o">=</span> <span class="n">BigramLanguageModel</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
<span class="n">bm</span> <span class="o">=</span> <span class="n">bigram_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># TODO: your code below</span>
<span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">bm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>loss: 4.66
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
<p>From our answer in Q1.1.6, we know that a model with logits = 0 has a loss equivalent to $(T-1)\log{V}$. Per token, this would be approximately equal to $\log{V} = \log{65} \approx 4.17$. However, since we initialized the model with random logits, we would expect our loss to be similar to a model with initialized logits of 0 since the model has not received any training on the data itself. Furthermore, having a loss larger than the theoretical value where all the logits are 0 is not unexpected since the assumption of uniform prediction over the vocabulary may be better than a completely random assignment for the logits.</p>
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Question-1.1.9:-Training-your-bigram-model">Question 1.1.9: Training your bigram model<a class="anchor-link" href="#Question-1.1.9:-Training-your-bigram-model"></a></h4><p>Train your bigram model for <code>SMALL_ITERS</code> iterations. Plot and interpret the loss curve.</p>
<p>Our train loss gets down to around 2.5 after 1000 iterations.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># create a PyTorch optimizer</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-2</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">bigram_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="n">eval_interval</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">SMALL_ITERS</span><span class="p">)):</span>

    <span class="c1"># every once in a while evaluate the loss on train and val sets</span>
    <span class="k">if</span> <span class="n">it</span> <span class="o">%</span> <span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">it</span> <span class="o">==</span> <span class="n">SMALL_ITERS</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"iteration </span><span class="si">{</span><span class="n">it</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">estimate_loss</span><span class="p">(</span><span class="n">bm</span><span class="p">,</span> <span class="n">EVAL_ITERS</span><span class="p">,</span> <span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"step </span><span class="si">{</span><span class="n">it</span><span class="si">}</span><span class="s2">: train loss </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="s1">'train'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, val loss </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="s1">'val'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># sample a batch of data</span>
    <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s1">'train'</span><span class="p">,</span> <span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

    <span class="c1"># evaluate the loss</span>
    <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">bm</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
    <span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  0%|          | 0/1000 [00:00&lt;?, ?it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 0
step 0: train loss 4.6454, val loss 4.6532
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 20%|        | 201/1000 [00:00&lt;00:02, 328.48it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 200
step 200: train loss 2.8995, val loss 2.9157
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 42%|     | 425/1000 [00:01&lt;00:01, 408.90it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 400
step 400: train loss 2.5581, val loss 2.5770
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 59%|    | 591/1000 [00:01&lt;00:00, 574.95it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 600
step 600: train loss 2.4962, val loss 2.5211
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 80%|  | 801/1000 [00:01&lt;00:00, 423.09it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 800
step 800: train loss 2.4797, val loss 2.5081
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>100%|| 1000/1000 [00:02&lt;00:00, 436.61it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 999
step 999: train loss 2.4728, val loss 2.5016
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"iteration"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Training loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
<p>From the plot above,we can see the loss curve is monotonically decreasing with iterations. However, the rate of decrease slows considerably by the 400-iteration mark. The loss begins around 4.7 and decreases to a value of approximately 2.5, which aligns with adjacent results.</p>
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Note that these models can take up a lot of memory on the GPU. As you go through this assignment, you may want to free the models after you train them using code along the lines of</p>
<pre><code>model.to('cpu')
torch.cuda.empty_cache()
</code></pre>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="1.2:-Token-Embeddings:-going-from-discrete-tokens-to-continuous-latent-spaces">1.2: Token Embeddings: going from discrete tokens to continuous latent spaces<a class="anchor-link" href="#1.2:-Token-Embeddings:-going-from-discrete-tokens-to-continuous-latent-spaces"></a></h3><p>In the look up table formulation of the bigram model, we are modelling the logits of the next token distribution independently for each token, even if two tokens are extremely similar to each other.
One way around this problem is to learn an embedding of the discrete tokens into $\mathbb{R}^{D}$, and then to run multi-class logistic regression on top of this learned embedding.</p>
<p>More precisely, if we have a vocabulary of tokens of size $V$ that we choose to embed in a Euclidean embedding space of dimension $D$, we can parameterize the distribution of the next token if the current token is $v$ according to
\begin{align*}
  \mathrm{Cat}\Big( \mathrm{softmax} (\beta X_v) \Big),
\end{align*}
where $X_v \in \mathbb{R}^{D}$ is the learned embedding of token $v$ into $\mathbb{R}^{D}$ and $\beta \in \mathbb{R}^{V \times D}$. Notice that if $X$ were a fixed design matrix this formulation would be equivalent to multi-class logistic regression. However, both $X$ and $\beta$ are learnable parameters.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Question-1.2.1:-Implement-BigramWithWordEmbeddingsLM">Question 1.2.1: Implement BigramWithWordEmbeddingsLM<a class="anchor-link" href="#Question-1.2.1:-Implement-BigramWithWordEmbeddingsLM"></a></h4><p>Implement a bigram languge model that uses a linear readout from a low dimensional Euclidean embedding of each token to parameterize the logits of the next token distribution, instead of parameterizing the logits of the next token distribution directly. It should have almost the same implementation as <code>BigramLanguageModel</code> from Question 1.1.6, except <code>init</code> should also take in an <code>embed_size</code>, and the <code>forward</code> method will need to be modified.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">BigramWithWordEmbeddingsLM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
<span class="w">      </span><span class="sd">"""</span>
<span class="sd">      Args:</span>
<span class="sd">        vocab_size: int, size of the vocabulary</span>
<span class="sd">        embed_size: int, dimension of the word embedding (D)</span>
<span class="sd">      """</span>
      <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
      <span class="c1">#TODO, your code here</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">embed_size</span> <span class="o">=</span> <span class="n">embed_size</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">logits_table</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
      <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">          token_ids: (B, T) token ids that make up the context (batch has size B, each entry in the batch has length T)</span>
<span class="sd">          targets: (B, T) token ids corresponding to the target of each context in token_ids</span>

<span class="sd">        Returns:</span>
<span class="sd">          logits: (B, T, V), logits[b,t, :] gives the length V vector of logits for the next token prediction in string b up to t tokens</span>
<span class="sd">          loss: scalar, negative log likelihood of target given context</span>
<span class="sd">        """</span>
        <span class="c1"># TODO, your code here</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logits_table</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word_embeddings</span><span class="p">(</span><span class="n">token_ids</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">targets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">targets</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">          token_ids: (B, T) tensor of token ids to provide as context</span>
<span class="sd">          max_new_tokens: int, maximum number of new tokens to generate</span>

<span class="sd">        Returns:</span>
<span class="sd">          (B, T+max_new_tokens) tensor of context with new tokens appended</span>
<span class="sd">        """</span>
        <span class="c1">#TODO</span>
        <span class="c1"># your code below</span>

        <span class="n">B</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">new_token_ids</span> <span class="o">=</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">):</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logits_table</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word_embeddings</span><span class="p">(</span><span class="n">new_token_ids</span><span class="p">))</span>
            <span class="n">new_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">new_token_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">new_token_ids</span><span class="p">,</span> <span class="n">new_token</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_token_ids</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Question-1.2.2:-Training-your-bigram-model-with-word-embeddings">Question 1.2.2: Training your bigram model with word embeddings<a class="anchor-link" href="#Question-1.2.2:-Training-your-bigram-model-with-word-embeddings"></a></h4><p>Train your bigram model with word embeddings for <code>SMALL_ITERS</code> iterations. Plot and interpret the loss curve. How does the final loss compare to that of the bigram model without embeddings? Why do you think this is?</p>
<p>Our train loss gets down to around 2.5 after 1000 iterations.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">bigram_model_embed</span> <span class="o">=</span> <span class="n">BigramWithWordEmbeddingsLM</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
<span class="n">bm_e</span> <span class="o">=</span> <span class="n">bigram_model_embed</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-2</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">bigram_model_embed</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="n">eval_interval</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">SMALL_ITERS</span><span class="p">)):</span>

    <span class="c1"># every once in a while evaluate the loss on train and val sets</span>
    <span class="k">if</span> <span class="n">it</span> <span class="o">%</span> <span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">it</span> <span class="o">==</span> <span class="n">SMALL_ITERS</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"iteration </span><span class="si">{</span><span class="n">it</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">estimate_loss</span><span class="p">(</span><span class="n">bm_e</span><span class="p">,</span> <span class="n">EVAL_ITERS</span><span class="p">,</span> <span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"step </span><span class="si">{</span><span class="n">it</span><span class="si">}</span><span class="s2">: train loss </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="s1">'train'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, val loss </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="s1">'val'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># sample a batch of data</span>
    <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s1">'train'</span><span class="p">,</span> <span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

    <span class="c1"># evaluate the loss</span>
    <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">bm_e</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
    <span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  0%|          | 0/1000 [00:00&lt;?, ?it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 0
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  5%|         | 54/1000 [00:00&lt;00:04, 192.67it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 0: train loss 4.3316, val loss 4.3335
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 22%|       | 224/1000 [00:00&lt;00:02, 303.75it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 200
step 200: train loss 2.4721, val loss 2.4930
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 38%|      | 375/1000 [00:01&lt;00:01, 376.69it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 400
step 400: train loss 2.4644, val loss 2.4947
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 58%|    | 582/1000 [00:01&lt;00:00, 432.35it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 600
step 600: train loss 2.4620, val loss 2.4883
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 80%|  | 801/1000 [00:02&lt;00:00, 339.08it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 800
step 800: train loss 2.4595, val loss 2.4935
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>100%|| 1000/1000 [00:02&lt;00:00, 345.25it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 999
step 999: train loss 2.4584, val loss 2.4927
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"iteration"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Training loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
<p>From the plot above, we can see the model begins at a similar loss value and ends at a very similar loss value to the bigram model without embeddings. However, it reaches this loss value much quicker (approximately 100 iterations).</p>
<p>We note that the loss values are similar because of they are fundamentally performing the same task. They both use the current token to predict the next token (Markov property). The only difference between these models is that one will use a lookup table of size $V \times V$ whereas the other will use a $V \times D$ embedding matrix and a $D \times V$ projection matrix. Since they both utilize similar methods to predict the next token, the overall loss result is expected to be similar.</p>
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="1.3:-Attention:-Relaxing-Markovian-assumptions-to-transmit-information-across-the-sequence-length">1.3: Attention: Relaxing Markovian assumptions to transmit information across the sequence length<a class="anchor-link" href="#1.3:-Attention:-Relaxing-Markovian-assumptions-to-transmit-information-across-the-sequence-length"></a></h3><p>A major problem with the bigram models of Sections 1.1 and 1.2 was that they were Markovian: the distribution of the next token was determined entirely by the current token! The attention mechanism provides a way to extract information between the previous tokens in the context to provide a better parameterization for the distribution of the next token.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Question-1.3.1:-Averaging-over-word-embeddings">Question 1.3.1: Averaging over word embeddings<a class="anchor-link" href="#Question-1.3.1:-Averaging-over-word-embeddings"></a></h4><p>One simple way to pool information would simply be to average the embeddings!</p>
<p>Your TODO: Add comments to the the code snippet below. Write a description here explaining why the code is mathematically equivalent to averaging the embeddings of the previous tokens and the current token.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
<p>The code is mathematically equivalent to averaging the embeddings of the previous and current tokens because of softmax and the random initialization of 0 for the attn_weights. Since the softmax function is applied to each row of the attn_weights, we know that the row dimension will be normalized based on number of embeddings that have been seen. Thus, multiplying this by the word embeddings creates a weighted sum of each of the embeddings weighted the total number of embeddings that have come before it (and including it). This can be seen in the final output, as the first two entries are unchanged, but the rest of the values are weighted sums of the values before and up to the current embedding.</p>
<hr/>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[17]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># average word embedding via matrix multiply and softmax</span>
<span class="n">small_batch_size</span> <span class="o">=</span> <span class="mi">4</span>              <span class="c1"># B</span>
<span class="n">small_context_window_size</span> <span class="o">=</span> <span class="mi">8</span>     <span class="c1"># T</span>
<span class="n">small_embed_size</span> <span class="o">=</span> <span class="mi">2</span>              <span class="c1"># D</span>

<span class="c1"># make "synthetic" word embeddings (for illustration purposes only)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">small_batch_size</span><span class="p">,</span> <span class="n">small_context_window_size</span><span class="p">,</span> <span class="n">small_embed_size</span><span class="p">)</span>

<span class="c1"># X is a sample small batch of size B. Each sample has a context window of size T and each word is represented by a D-dimensional embedding.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># tril is a lower triangular matrix of size T x T. This is the attention mask that ensures the model only looks at things we've seen already.</span>
<span class="n">tril</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">small_context_window_size</span><span class="p">,</span> <span class="n">small_context_window_size</span><span class="p">))</span>

<span class="c1"># attn_weights is a matrix of size T x T. This is the attention weights that will be used to compute the weighted average of the embeddings.</span>
<span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">small_context_window_size</span><span class="p">,</span> <span class="n">small_context_window_size</span><span class="p">))</span>

<span class="c1"># fill in the attention weights using the lower triangular mask. For values we haven't seen yet, we set the attention weight to -inf which will go to 0 after softmax.</span>
<span class="n">attn_weights</span> <span class="o">=</span> <span class="n">attn_weights</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">tril</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">'-inf'</span><span class="p">))</span>

<span class="c1"># softmax the attention weights. Weights will sum to 1 with values evenly distributed among the words we've seen.</span>
<span class="n">attn_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Multiplying the attention weights by the embeddings will give us the weighted average of the embeddings.</span>
<span class="n">avg_embeddings</span> <span class="o">=</span> <span class="n">attn_weights</span> <span class="o">@</span> <span class="n">X</span>

<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">""</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">avg_embeddings</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([4, 8, 2])
tensor([[ 0.5318, -0.4167],
        [-0.4982,  0.0156],
        [ 1.1415, -0.1181],
        [ 0.2128,  2.3295],
        [ 0.4573,  0.7488],
        [ 0.3794, -0.2672],
        [-1.2237,  2.7066],
        [ 0.5399, -0.5297]])

tensor([[ 0.5318, -0.4167],
        [ 0.0168, -0.2006],
        [ 0.3917, -0.1731],
        [ 0.3470,  0.4525],
        [ 0.3690,  0.5118],
        [ 0.3708,  0.3820],
        [ 0.1430,  0.7140],
        [ 0.1926,  0.5586]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="1.3.2:-Single-headed-scaled-$(Q,K,V)$-attention">1.3.2: Single-headed scaled $(Q,K,V)$-attention<a class="anchor-link" href="#1.3.2:-Single-headed-scaled-$(Q,K,V)$-attention"></a></h4><p>A more sophisticated approach than simply averaging over previous word embeddings is single-headed (Query, Key, Value) scaled attention.
That is, we now summarize the information contained in a length $T$ sequence of tokens that have been embeded into $X \in \mathbb{R}^{T \times D}$ according to
\begin{equation}
   \mathrm{SoftmaxAcrossRows} \Bigg( \frac{\mathrm{CausalMask}\Big(X U_q^\top U_k X^\top \Big)}{\sqrt{K}} \Bigg) \Big( X V^\top \Big),
\end{equation}
where $U_q, U_k \in \mathbb{R}^{K \times D}$, $V \in \mathbb{R}^{D \times D}$, and $K$ is the "head size".</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="Question-1.3.2.1">Question 1.3.2.1<a class="anchor-link" href="#Question-1.3.2.1"></a></h5><p>In the limiting case where $U_q$ and $U_k$ are all zeros, and $V = I_{D}$, what does $(U_q, U_k, V)$ attention simplify to?</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
<p>In the following equation,</p>
<p>\begin{equation}
   \mathrm{SoftmaxAcrossRows} \Bigg( \frac{\mathrm{CausalMask}\Big(X U_q^\top U_k X^\top \Big)}{\sqrt{K}} \Bigg) \Big( X V^\top \Big),
\end{equation}</p>
<p>If $U_q$ and $U_k$ are all zeros, then:</p>
<p>\begin{equation}
   \mathrm{SoftmaxAcrossRows} \Bigg( \frac{0}{\sqrt{K}} \Bigg) \Big( X V^\top \Big),
\end{equation}</p>
<p>Which is equivalent to</p>
<p>\begin{equation}
   \mathrm{SoftmaxAcrossRows} \Big( 0 \Big) \Big( X V^\top \Big),
\end{equation}</p>
<p>If $V = I_{D}$, then</p>
<p>\begin{equation}
   \mathrm{SoftmaxAcrossRows} \Big( 0 \Big) \Big( X\Big),
\end{equation}</p>
<p>But from Q1.3.1, we know that the softmax of the 0 matrix is the attn_weights from Q1.3.1, and thus we get the same thing we had before.</p>
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="Question-1.3.2.2:-Implement-single-headed-scaled-$(U_q,U_k,V)$-attention.">Question 1.3.2.2: Implement single-headed scaled $(U_q,U_k,V)$-attention.<a class="anchor-link" href="#Question-1.3.2.2:-Implement-single-headed-scaled-$(U_q,U_k,V)$-attention."></a></h5><p>Complete the below code so the <code>forward</code> method returns single-headed scaled $(U_q,U_k,V)$-attention.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Head</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">""" one head of self-attention """</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">context_window_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="mi">384</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">          head_size: int, size of the head embedding dimension (K)</span>
<span class="sd">          context_window_size: int, number of tokens considered in the past for attention (T)</span>
<span class="sd">          embed_size: int, size of the token embedding dimension (D)</span>
<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">head_size</span> <span class="o">=</span> <span class="n">head_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">query</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># not a param of the model, so registered as a buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">'tril'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">context_window_size</span><span class="p">,</span> <span class="n">context_window_size</span><span class="p">)))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">          x: (B,T,D) tensor of token embeddings</span>

<span class="sd">        Returns:</span>
<span class="sd">          (B,T,D) tensor of attention-weighted token embeddings</span>
<span class="sd">        """</span>
        <span class="c1"># TODO: your code here</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_size</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">query</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">attn_scores</span> <span class="o">=</span> <span class="n">query</span><span class="nd">@key</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">causal_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tril</span><span class="p">[:</span><span class="n">T</span><span class="p">,</span> <span class="p">:</span><span class="n">T</span><span class="p">][</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="n">attn_scores</span> <span class="o">=</span> <span class="n">attn_scores</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">causal_mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">'-inf'</span><span class="p">))</span>
        <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn_scores</span> <span class="o">/</span> <span class="p">(</span><span class="n">K</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">attn_weights</span><span class="nd">@value</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="Question-1.3.2.3:-Implement-a-single-headed-attention-language-model">Question 1.3.2.3: Implement a single-headed attention language model<a class="anchor-link" href="#Question-1.3.2.3:-Implement-a-single-headed-attention-language-model"></a></h5><p>Complete the code below. Note that because the transformer has no idea where tokens are occuring in space, we have also added in position embeddings.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SingleHeadedAttentionLM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">context_window_size</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="mi">384</span><span class="p">):</span>
<span class="w">      </span><span class="sd">"""</span>
<span class="sd">      Args:</span>
<span class="sd">        vocab_size: int, size of the vocabulary (V)</span>
<span class="sd">        context_window_size: int, number of tokens considered in the past for attention (T)</span>
<span class="sd">        head_size: int, size of the head embedding dimension (K)</span>
<span class="sd">        embed_size: int, size of the token embedding dimension (D)</span>
<span class="sd">      """</span>
      <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding_table</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">position_embedding_table</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">context_window_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">context_window_size</span> <span class="o">=</span> <span class="n">context_window_size</span>

      <span class="c1"># TODO: your code below</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">atten_head</span> <span class="o">=</span> <span class="n">Head</span><span class="p">(</span><span class="n">head_size</span><span class="p">,</span> <span class="n">context_window_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">          token_ids: (B, T) token ids that make up the context (batch has size B, each entry</span>
<span class="sd">                     in the batch has length T)</span>
<span class="sd">          targets: (B, T) token ids corresponding to the target of each context in token_ids</span>

<span class="sd">        Returns:</span>
<span class="sd">          logits: (B, T, V) logits[b,t] gives the length V vector of logits for the next token</span>
<span class="sd">                   prediction in string b up to t tokens</span>
<span class="sd">          loss: scalar, negative log likelihood of target given context</span>
<span class="sd">        """</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># (batch size, length)</span>
        <span class="n">tok_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding_table</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span> <span class="c1"># (B,T,D)</span>
        <span class="n">pos_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embedding_table</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span> <span class="c1"># (T,D)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tok_emb</span> <span class="o">+</span> <span class="n">pos_emb</span> <span class="c1"># (B,T,D)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">atten_head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># (B,T,D)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># (B,T,V)</span>

        <span class="c1"># TODO: your code here</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">targets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">targets</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">          token_ids: (B, T) tensor of token ids to provide as context</span>
<span class="sd">          max_new_tokens: int, maximum number of new tokens to generate</span>

<span class="sd">        Returns:</span>
<span class="sd">          (B, T+max_new_tokens) tensor of context with new tokens appended</span>
<span class="sd">        """</span>
        <span class="c1">#TODO</span>
        <span class="c1"># your code below</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">new_token_ids</span> <span class="o">=</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">):</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">new_token_ids</span><span class="p">)</span>
            <span class="n">new_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">new_token_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">new_token_ids</span><span class="p">,</span> <span class="n">new_token</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_token_ids</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Train your new <code>SingleHeadedAttentionLM</code> for <code>SMALL_ITERS</code> training iterations and plot the loss curve.
The <code>head_size</code> shouldn't matter too much, we just use the <code>embedding_size</code>.
Do you seen an improvement compared to your <code>BigramLanguageModel</code>? Discuss.</p>
<p>Note: you may want to modify the learning rate. Training for <code>SMALL_ITERS</code> with a learning rate of <code>6e-4</code>, we can get to a train loss of around 2.3.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">embed_size</span> <span class="o">=</span> <span class="mi">384</span>
<span class="n">sha_model</span> <span class="o">=</span> <span class="n">SingleHeadedAttentionLM</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
<span class="n">sham</span> <span class="o">=</span> <span class="n">sha_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">6e-4</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">sha_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="n">eval_interval</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">SMALL_ITERS</span><span class="p">)):</span>

    <span class="c1"># every once in a while evaluate the loss on train and val sets</span>
    <span class="k">if</span> <span class="n">it</span> <span class="o">%</span> <span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">it</span> <span class="o">==</span> <span class="n">SMALL_ITERS</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"iteration </span><span class="si">{</span><span class="n">it</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">estimate_loss</span><span class="p">(</span><span class="n">sham</span><span class="p">,</span> <span class="n">EVAL_ITERS</span><span class="p">,</span> <span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"step </span><span class="si">{</span><span class="n">it</span><span class="si">}</span><span class="s2">: train loss </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="s1">'train'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, val loss </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="s1">'val'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span>
        <span class="p">)</span>

    <span class="c1"># sample a batch of data</span>
    <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s2">"train"</span><span class="p">,</span> <span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

    <span class="c1"># evaluate the loss</span>
    <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">sham</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
    <span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  0%|          | 0/1000 [00:00&lt;?, ?it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 0
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  1%|          | 12/1000 [00:00&lt;01:00, 16.26it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 0: train loss 4.1927, val loss 4.1915
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 19%|        | 191/1000 [00:02&lt;00:08, 99.40it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 200
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 21%|        | 212/1000 [00:03&lt;00:20, 39.35it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 200: train loss 2.5919, val loss 2.5996
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 39%|      | 392/1000 [00:05&lt;00:06, 99.38it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 400
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 41%|     | 413/1000 [00:06&lt;00:14, 40.08it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 400: train loss 2.5403, val loss 2.5580
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 59%|    | 590/1000 [00:08&lt;00:04, 99.95it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 600
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 61%|    | 612/1000 [00:09&lt;00:09, 40.78it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 600: train loss 2.4720, val loss 2.4958
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 80%|  | 799/1000 [00:11&lt;00:02, 99.59it/s] </pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 800
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 82%| | 819/1000 [00:12&lt;00:04, 37.58it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 800: train loss 2.3846, val loss 2.4250
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>100%|| 995/1000 [00:13&lt;00:00, 100.65it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 999
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>100%|| 1000/1000 [00:14&lt;00:00, 67.94it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 999: train loss 2.3517, val loss 2.3903
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[22]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"iteration"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Training loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
<p>From our results and plots from the bigram models, we can see that using a single head of attention is not a significant improvement over just the bigram model. We note that the final loss values are similar; however, the loss of the single headed attention model does not appear to slow as heavily as the bigram models. This could imply that more training time could lead to a better result, as attention may take much longer to refine. Finally, we note that with a single head of attention, the model may not be able to effectively capture complex relationships in Shakespeare's prose. With increasing model complexity, we may see even more improvements.</p>
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="1.3.3:-Multi-headed-attention">1.3.3: Multi-headed attention<a class="anchor-link" href="#1.3.3:-Multi-headed-attention"></a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="Question-1.3.3.1:-Implement-multi-headed-attention">Question 1.3.3.1: Implement multi-headed attention<a class="anchor-link" href="#Question-1.3.3.1:-Implement-multi-headed-attention"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">""" multiple heads of self-attention in parallel """</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context_window_size</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">head_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="mi">384</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">            context_window_size: int, number of tokens considered in the past for attention (T)</span>
<span class="sd">            num_heads: int, number of heads (H)</span>
<span class="sd">            head_size: int, size of the head embedding dimension</span>
<span class="sd">            embed_size: int, size of the token embedding dimension</span>
<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># TODO, your code below</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">Head</span><span class="p">(</span><span class="n">head_size</span><span class="p">,</span> <span class="n">context_window_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_heads</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_size</span><span class="o">*</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># TODO, your code below</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">head_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span>
        <span class="n">head_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">head</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">heads</span><span class="p">]</span>
        <span class="n">head_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">head_outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">head_outputs</span> <span class="o">=</span> <span class="n">head_outputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">head_outputs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="Question-1.3.3.2:-Implement-a-multi-headed-attention-LM">Question 1.3.3.2: Implement a multi-headed attention LM<a class="anchor-link" href="#Question-1.3.3.2:-Implement-a-multi-headed-attention-LM"></a></h5><p>Fill in the code below to create a language model that outputs its logits for next token prediction using multi-headed attention. Train your model for <code>SMALL_ITERS</code> training iterations. Compare the results with the single-headed attention model. Do you see an improvement?</p>
<p>We get to a train loss of around 2 after 1000 iterations, which takes around 1.5 minutes on a T4 GPU.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[24]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MultiHeadedAttentionLM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">context_window_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="mi">384</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">6</span><span class="p">):</span>
      <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">head_size</span> <span class="o">=</span> <span class="n">embed_size</span> <span class="o">//</span> <span class="n">num_heads</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">context_window_size</span> <span class="o">=</span> <span class="n">context_window_size</span>
      <span class="c1"># TODO: your code below</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding_table</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">position_embedding_table</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">context_window_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">multi_head_attention</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">context_window_size</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">          token_ids: (B, T) token ids that make up the context (batch has size B, each entry in the</span>
<span class="sd">                     batch has length T)</span>
<span class="sd">          targets: (B, T) token ids corresponding to the target of each context in token_ids</span>

<span class="sd">        Returns:</span>
<span class="sd">          logits: (B, T, V), logits[b,t] gives the length V vector of logits for the next token</span>
<span class="sd">                  prediction in string b up to t tokens</span>
<span class="sd">          loss: scalar, negative log likelihood of target given context</span>
<span class="sd">        """</span>
        <span class="c1"># TODO: your code below</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">tok_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding_table</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span>
        <span class="n">pos_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embedding_table</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tok_emb</span> <span class="o">+</span> <span class="n">pos_emb</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_head_attention</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">targets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">targets</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">          token_ids: (B, T) tensor of token ids to provide as context</span>
<span class="sd">          max_new_tokens: int, maximum number of new tokens to generate</span>

<span class="sd">        Returns:</span>
<span class="sd">          (B, T+max_new_tokens) tensor of context with new tokens appended</span>
<span class="sd">        """</span>
        <span class="c1"># TODO: your code below</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">context_window_size</span><span class="p">:</span>
                <span class="n">token_ids</span> <span class="o">=</span> <span class="n">token_ids</span><span class="p">[:,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">context_window_size</span><span class="p">:]</span>
            <span class="n">B</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">new_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">token_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">token_ids</span><span class="p">,</span> <span class="n">new_token</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">token_ids</span>
        
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[25]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Initialize model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MultiHeadedAttentionLM</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># create a PyTorch optimizer</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">6e-4</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="n">eval_interval</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">SMALL_ITERS</span><span class="p">)):</span>

    <span class="c1"># every once in a while evaluate the loss on train and val sets</span>
    <span class="k">if</span> <span class="n">it</span> <span class="o">%</span> <span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">it</span> <span class="o">==</span> <span class="n">SMALL_ITERS</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"iteration </span><span class="si">{</span><span class="n">it</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">estimate_loss</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">EVAL_ITERS</span><span class="p">,</span> <span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"step </span><span class="si">{</span><span class="n">it</span><span class="si">}</span><span class="s2">: train loss </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="s1">'train'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, val loss </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="s1">'val'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># sample a batch of data</span>
    <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s1">'train'</span><span class="p">,</span> <span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

    <span class="c1"># evaluate the loss</span>
    <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
    <span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  0%|          | 0/1000 [00:00&lt;?, ?it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 0
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  0%|          | 5/1000 [00:02&lt;07:03,  2.35it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 0: train loss 4.1585, val loss 4.1596
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 20%|        | 200/1000 [00:10&lt;00:30, 25.90it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 200
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 20%|        | 203/1000 [00:13&lt;03:57,  3.36it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 200: train loss 2.4435, val loss 2.4729
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 40%|      | 398/1000 [00:20&lt;00:23, 26.11it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 400
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 40%|      | 404/1000 [00:23&lt;02:10,  4.58it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 400: train loss 2.1948, val loss 2.2595
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 60%|    | 599/1000 [00:30&lt;00:15, 26.08it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 600
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 60%|    | 605/1000 [00:33&lt;01:26,  4.56it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 600: train loss 2.0513, val loss 2.1473
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 80%|  | 800/1000 [00:41&lt;00:07, 26.14it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 800
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 80%|  | 803/1000 [00:43&lt;00:58,  3.38it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 800: train loss 1.9827, val loss 2.1064
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>100%|| 998/1000 [00:51&lt;00:00, 25.88it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>iteration 999
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>100%|| 1000/1000 [00:53&lt;00:00, 18.54it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 999: train loss 1.9331, val loss 2.0736
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[26]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"iteration"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Training loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
<p>Compared to the model with a single head of attention, we can see losses are noticeably smaller for the multi-headed attention model. This makes sense as a multi-headed attention model is better suited to capture numerous complex relationships between tokens, which is to be expected with text written by Shakespeare.</p>
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="1.4:-The-Transformer-Architecture:-combining-attention-with-deep-learning">1.4: The Transformer Architecture: combining attention with deep learning<a class="anchor-link" href="#1.4:-The-Transformer-Architecture:-combining-attention-with-deep-learning"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[27]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># run this cell to initialize this deep learning module that you should use in the code your write later</span>
<span class="c1"># you don't need to edit this layer</span>
<span class="k">class</span><span class="w"> </span><span class="nc">FeedForward</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">""" a simple linear layer followed by a non-linearity</span>
<span class="sd">        Given to you, you don't need to write any code here!</span>
<span class="sd">    """</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">embed_size</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Question-1.4.1:-Implement-a-transformer-block">Question 1.4.1: Implement a transformer block<a class="anchor-link" href="#Question-1.4.1:-Implement-a-transformer-block"></a></h4><p>Complete the code below to implement a transformer block</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>To make the your implemenation easier to train, we have added two deep learning best practices:</p>
<ol>
<li><p>Residual connections.</p>
<p>In the <code>forward</code> method of the <code>TransformerBlock</code>, we have implemented a residual connection of the form</p>
<p>\begin{align*}
 x \mapsto x + f(x)
 \end{align*}</p>
<p>where $f$ is a nonlinear function. The idea is that every layer is some adjustment of the identity function, which guards against vanishing gradients in a deep network during back propogation, especially at initialization.</p>
</li>
<li><p>Prenorm via <code>LayerNorm</code></p>
<p>Also in the <code>forward</code> method of the <code>TransformerBlock</code>, the nonlinearity first applied a <code>LayerNorm</code> to its arguments. The <code>LayerNorm</code> basically standardizes the activations in that layer so that they have mean 0 and variance 1. Doing so is very helpful for numerical stability, espeically of the gradients.</p>
</li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[28]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">TransformerBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">""" Transformer block: communication across sequence length, followed by communication across embedding space</span>
<span class="sd">        Uses multi-headed attention</span>
<span class="sd">    """</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">context_window_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="mi">384</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">embed_size</span><span class="p">)</span>

        <span class="c1"># TODO: your code below</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">atten_heads</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">context_window_size</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">embed_size</span> <span class="o">//</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">atten_heads</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ln1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="c1"># communication over sequence length</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">feed_forward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ln2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="c1"># communication across embedding space</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Question-1.4.2:-Implement-your-baseline-transformer-model">Question 1.4.2: Implement your baseline transformer model<a class="anchor-link" href="#Question-1.4.2:-Implement-your-baseline-transformer-model"></a></h4><p>We now stack 6 <code>TransformerBlocks</code> (with a final layer norm applied after the blocks but before the logits) to create our basline <code>TransformerLM</code>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[29]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">TransformerLM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">context_window_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="mi">384</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">          Args:</span>
<span class="sd">              vocab_size: int, number of tokens in the vocabulary (V)</span>
<span class="sd">              context_window_size: int, size of the context window (T)</span>
<span class="sd">              embed_size: int, embedding size (D)</span>
<span class="sd">              num_heads: int, number of heads (H)</span>
<span class="sd">              n_layers: int, number of layers (M)</span>
<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding_table</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">position_embedding_table</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">context_window_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span>
            <span class="n">TransformerBlock</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span>
                             <span class="n">context_window_size</span><span class="p">,</span>
                             <span class="n">embed_size</span><span class="o">=</span><span class="n">embed_size</span><span class="p">,</span>
                             <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)])</span>

        <span class="c1"># final layer norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln_f</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

        <span class="c1"># good initialization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_init_weights</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">):</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Agrgs:</span>
<span class="sd">            token_ids: tensor of integers, provides the contet, shape (B, T)</span>
<span class="sd">            targets: tensor of integers, provides the tokens we are preidcitng, shape (B, T)</span>
<span class="sd">        """</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># token_ids and targets are both (B, T) tensor of integers</span>
        <span class="n">tok_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding_table</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span> <span class="c1"># (B, T, D)</span>
        <span class="n">pos_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embedding_table</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span> <span class="c1"># (T, D)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tok_emb</span> <span class="o">+</span> <span class="n">pos_emb</span> <span class="c1"># (B, T, D)</span>

        <span class="c1"># TODO: your code below</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln_f</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">targets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">targets</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">            token_ids: tensor of integers forming the context, shape (B, T)</span>
<span class="sd">            max_new_tokens: int, max number of tokens to generate</span>
<span class="sd">        """</span>
        <span class="c1"># TOOD, your code below</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">:</span>
                <span class="n">token_ids</span> <span class="o">=</span> <span class="n">token_ids</span><span class="p">[:,</span> <span class="o">-</span><span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">:]</span>
            <span class="n">logits</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> 
            <span class="n">next_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">token_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">token_ids</span><span class="p">,</span> <span class="n">next_token</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">token_ids</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Train your <code>TransformerLM</code> for <code>LARGE_ITERS</code> iterations and plot the loss curve. You may want to change the learning rate.</p>
<p>We used a learning rate of <code>1e-4</code> and got to a final train loss of around 1.4 in around 15 minutes of training on a T4 GPU.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[30]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trans</span> <span class="o">=</span> <span class="n">TransformerLM</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">)</span>
<span class="n">tlm</span> <span class="o">=</span> <span class="n">trans</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="c1"># TODO, your code below</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">tlm</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">eval_interval</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">tlm</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">LARGE_ITERS</span><span class="p">)):</span>
    <span class="c1"># Evaluate</span>
    <span class="k">if</span> <span class="n">it</span> <span class="o">%</span> <span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">estimate_loss</span><span class="p">(</span><span class="n">tlm</span><span class="p">,</span> <span class="n">EVAL_ITERS</span><span class="p">,</span> <span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"step </span><span class="si">{</span><span class="n">it</span><span class="si">}</span><span class="s2">: train loss </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="s1">'train'</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, val loss </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="s1">'val'</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
    <span class="c1"># Forward/backward/update</span>
    <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s1">'train'</span><span class="p">,</span> <span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">tlm</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"final training loss ="</span><span class="p">,</span> <span class="n">loss_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>  0%|          | 0/2000 [00:00&lt;?, ?it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 0: train loss 4.233, val loss 4.232
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 10%|         | 200/2000 [01:24&lt;09:35,  3.13it/s] </pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 200: train loss 2.486, val loss 2.496
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 20%|        | 400/2000 [02:48&lt;08:27,  3.15it/s]  </pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 400: train loss 2.291, val loss 2.312
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 30%|       | 600/2000 [04:12&lt;07:23,  3.15it/s]  </pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 600: train loss 2.016, val loss 2.075
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 40%|      | 800/2000 [05:36&lt;06:20,  3.15it/s]  </pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 800: train loss 1.799, val loss 1.922
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 50%|     | 1000/2000 [07:00&lt;05:23,  3.09it/s] </pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 1000: train loss 1.671, val loss 1.823
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 60%|    | 1200/2000 [08:25&lt;04:17,  3.11it/s]  </pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 1200: train loss 1.577, val loss 1.751
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 70%|   | 1400/2000 [09:50&lt;03:13,  3.10it/s]  </pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 1400: train loss 1.502, val loss 1.705
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 80%|  | 1600/2000 [11:15&lt;02:10,  3.07it/s]  </pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 1600: train loss 1.465, val loss 1.672
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre> 90%| | 1800/2000 [12:39&lt;01:03,  3.15it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>step 1800: train loss 1.420, val loss 1.628
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>100%|| 2000/2000 [14:03&lt;00:00,  2.37it/s]</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>final training loss = 1.380360722541809
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[39]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">losses</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[39]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>{'train': tensor(1.4201), 'val': tensor(1.6275)}</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Question-1.4.3:-Generating-text!">Question 1.4.3: Generating text!<a class="anchor-link" href="#Question-1.4.3:-Generating-text!"></a></h4><p>Now with our trained model, we can generate some text that is somewhat like the style of Shakespeare! Below we will do both unconditional and conditional generation.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[31]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># unconditional generation from the model</span>
<span class="n">start_context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">uncond_gen</span> <span class="o">=</span> <span class="p">(</span><span class="n">tlm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">start_context</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">decode</span><span class="p">(</span><span class="n">uncond_gen</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
Kecong and to her no heart,
Awaked, and my Crescy, declime, my betters'd
Upon mine to them.

DUCHESS OF YORK:
I knever duke a justague as great.

RICHARD:
This love to me neval it me.

DUKE OF AUMERLE:
Take it two cornsels to the discatch
Seemer I on think
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[32]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># conditional generation from the model</span>

<span class="n">context1</span> <span class="o">=</span> <span class="s2">"""ROMEO:</span>
<span class="s2">He jests at scars that never felt a wound.</span>
<span class="s2">But, soft! what light through yonder window breaks?</span>
<span class="s2">It is the east, and Juliet is the sun.</span>
<span class="s2">Arise, fair sun, and kill the envious moon,</span>
<span class="s2">Who is already sick and pale with grief,</span>
<span class="s2">That thou her maid art far more fair than she:</span>
<span class="s2">Be not her maid, """</span>

<span class="n">context1_tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">encode</span><span class="p">(</span><span class="n">context1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[33]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">cond_gen</span> <span class="o">=</span> <span class="p">(</span><span class="n">tlm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">context1_tokens</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">decode</span><span class="p">(</span><span class="n">cond_gen</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre> and wish may Romeo?
Beard loving arms so your on's sicre.

HERRMIONE:
Taken your short's royall about your armedly.

HENRY BOLINGOROKE:
By him, bruther, O, prince with his compats
To keep not down his not hath our in than yield,
But trikely which butwen th
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>TODO: Choose your own context from Shakespeare, and perform conditional generation from that text. Does this look reasonable to you? Why or why not?</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[35]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># TODO: your code here</span>

<span class="n">context2</span> <span class="o">=</span> <span class="s2">"""To be, or not to be: """</span>
<span class="n">context2_tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">encode</span><span class="p">(</span><span class="n">context2</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cond_gen2</span> <span class="o">=</span> <span class="p">(</span><span class="n">tlm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">context2_tokens</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">CONTEXT_WINDOW_SIZE</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">decode</span><span class="p">(</span><span class="n">cond_gen2</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre> feor I chek you will think
every is far absence: and espute forth I
never have strong to rupp-speed. She donem, the
Liver ptock, and be doubteat to the ochactor: you
must havim, then you shall, I did you wind.

First HusdY:
Peace for him
Thrips with here: 
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
<p>From the output above, we can see that it does not follow the traditional "To be or not to be" speech. However, we also note that some of the words are not formatted correctly (random capitalization) and many of them are not words featured in common or Shakspeare English. Therefore, this is not necessarily a reasonable representation of Shakespeare's prose. This is to be expected due to the highly unstructured and variable nature of Shakepeare's texts. Furthermore, there may not be enough data to train the model to understand the complex relationships between tokens.</p>
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Question-1.4.4">Question 1.4.4<a class="anchor-link" href="#Question-1.4.4"></a></h4><p>The negative log-likelihood (averaged per token) we have been using to train our models can be expressed as
\begin{equation*}
  L = -\frac{1}{T} \sum_{t = 1}^{T} \log p(s[t] | \text{context})
\end{equation*}
for some document $s$, where $s[t]$ is the $t$th token of the doc. The natural language processing (NLP) community often reports the quantity
\begin{equation*}
  \text{perplexity} = \exp(L).
\end{equation*}</p>
<p>Give an intuitive interpretation of what perplexity is. Why might it be a more intuitive or natual measure to report than negative log-likelihood? Does the reported perplexity of your trained <code>TransformerLM</code> model make sense in terms of samples it generates? (Be sure to distinguish betwen <code>train</code> and <code>validation</code> perplexity. Which of <code>train</code> and <code>val</code> perplexity is more helpful for understanding your generated samples? Why?). (<em>Hint: your answer to Question 1.1.6 may be helpful</em>).</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
<p>An intuitive interpretation of perplexity is the amount of uncertainty when the model attempts to pick the next token in a sequence. In other words, it represents how "perplexed" the model is when predicting the next token. For example, if a model has a perplexity of 5, then it had to uniformly choose between 5 different options at each token generating step. Naturally, a lower perplexity implies better predictive power. Finally, we note that a perplexity = 1 is a perfect performance, as the model had only one choice when generating a new token, which corresponds to a loss of 0.</p>
<p>This is more intuitive than negative log-likelihood since NLL is on a logarithmic scale which contrasts with the linear (and hence more intuitive) scale of perplexity. Furthermore, we note that NLL does not have an easily interpretable meaning when compared to perplexity. Thus perplexity is more intuitive than NLL for reporting model performance.</p>
<p>From the output above, we can calculate the approximate train and validation perplexity as $exp(1.4) = 4.06$ and $exp(1.62) = 5.05$ respectively. We can utilize the interpretation above to conclude that the model had to choose between approximately 4 to 5 choices per token during a prediction task. Based on the samples generated, this makes sense as the samples do resemble Shakespeare's style but are not perfect recreations of either common English or Shakespeare English.</p>
<p>Between train and val perplexity, we note validation perplexity is more helpful because it is based on text that wasn't used to tune the model. In other words, it measure how well the model generalizes to new text or new situations, which is the ultimate goal with prediction models. From Q1.1.6, we know that if each prediction is perfect, then the NLL is 0 and thus perplexity is 1. Since the data was used to tune the model parameters, the train perplexity may be subject to some degree of memorization. Thus, it may tend to make near-perfect predictions, which would skew the perplexity towards 1.</p>
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Part-2:-Mini-Project">Part 2: Mini-Project<a class="anchor-link" href="#Part-2:-Mini-Project"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Quick recap: So far we have</p>
<ol>
<li>Preprocessed the Shakespeare dataset by encoding individual characters into integer tokens.</li>
<li>Implemented single headed attention and then further generalized to multiheaded attention. We further combined multiheaded attention with deep learning to create the transformer architecture.</li>
<li>Trained our transformer and generated output that looks to be in the style of Shakespeare.</li>
</ol>
<p>Up to this point, the performance of our simple language model has clearly made a lot of progress. We can see that our model has learned to generate text that is close to the style of Shakespeare, although there are still many quirks and room for improvement.</p>
<h3 id="Project-Outline">Project Outline<a class="anchor-link" href="#Project-Outline"></a></h3><p>Find some area of possible improvement.
We interpret "improvement" quite loosely, but please state precisely why your proposed innovation might improve the model, and provide evidence that it does (or does not!) improve.
For your idea, <strong>formulate a hypothesis</strong> for why this change should result in a better model. <strong>Implement your changes</strong> and <strong>report any findings</strong>.</p>
<p><em>Notes</em>: As this assignment is being treated as a project, you should expect training to take longer than previous assignments. However, please use your judgement to decide what is reasonable. We will not expect you to run training procedures that take more than 2 hours on the free Google Colab computing resources and we certainly do not expect you to acquire additional compute. The proposed improvements should not solely rely on increased computing demands.</p>
<p><em>Hints</em>: There are many aspects to assessing a model. For example, not only is quality of generated text important, it is also of interest to reduce costs associated with training.</p>
<h3 id="Deliverables">Deliverables<a class="anchor-link" href="#Deliverables"></a></h3><p>In addition to a pdf of your python notebook, the submission for this project will be a written report no more than 4 pages in length using the <a href="https://neurips.cc/Conferences/2023/PaperInformation/StyleFiles">NeurIPS LaTex template</a>. Your report should include detailed analysis of the hypotheses you chose to test along with any conclusions.</p>
<p>The page limit for the report does not include bibliography or appendices. Make sure to keep the "ready for submission" option to help us grade anonymously. Your writeup should also contain a link to any code used to generate the project so that we can reference it while grading (Google Drive folder with colab notebooks or Github repo are both fine). You should have at least one plot in your main text (which is capped at 4 pages).</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Submission-Instructions">Submission Instructions<a class="anchor-link" href="#Submission-Instructions"></a></h2><p>You will generate two PDFs: one from Part 1, which involves completing this Colab to create a transformer baseline; and one from the mini-project in Part 2, which will be your write-up of no longer than 4 pages. Be sure to include a link to your code for Part 2 somewhere in your writeup.</p>
<p><strong>Combine the two PDFs into a single PDF and submit on gradescope. Tag your PDF correctly.</strong></p>
<p>If you work in a group of two, submit one assignment on gradescope and tag your group members. If you complete the assignment individually, submit as usual.</p>
</div>
</div>
</div>
</div>
</main>
</body>
</html>
