{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T01:46:44.408359Z",
     "start_time": "2025-03-14T01:46:41.269671Z"
    }
   },
   "source": [
    "# torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import collections\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers\n",
    "\n",
    "torch.manual_seed(305)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'mps'\n",
    "\n",
    "SMALL_ITERS = 1000\n",
    "LARGE_ITERS = 2000\n",
    "EVAL_ITERS = 100\n",
    "CONTEXT_WINDOW_SIZE = 256"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T01:46:47.366810Z",
     "start_time": "2025-03-14T01:46:47.361863Z"
    }
   },
   "source": [
    "input_file_path = 'data/full_shakespeare.txt'\n",
    "\n",
    "if not os.path.exists(input_file_path):\n",
    "    data_url = 'https://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt'\n",
    "    with open(input_file_path, 'w') as f:\n",
    "        f.write(requests.get(data_url).text)\n",
    "\n",
    "with open(input_file_path, 'r') as f:\n",
    "    data = f.read()\n",
    "print(f\"length of dataset in characters: {len(data):,}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 4,573,338\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T01:46:52.660374Z",
     "start_time": "2025-03-14T01:46:50.321719Z"
    }
   },
   "source": [
    "vocab_size = 2000\n",
    "\n",
    "# Define a BPE model\n",
    "tokenizer = Tokenizer(models.BPE(unk_token=\"<unk>\"))\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=True)\n",
    "tokenizer.decoder = decoders.ByteLevel()\n",
    "\n",
    "# Trainer with desired vocab size\n",
    "trainer = trainers.BpeTrainer(vocab_size=vocab_size, special_tokens=[\"<unk>\"])\n",
    "# data should be an iterator over your text lines or documents\n",
    "tokenizer.train_from_iterator([data], trainer=trainer)\n",
    "\n",
    "# Encode and decode functions\n",
    "def encode_bpe(text):\n",
    "    return tokenizer.encode(text).ids\n",
    "\n",
    "def decode_bpe(ids):\n",
    "    return tokenizer.decode(ids)\n",
    "\n",
    "# Example usage:\n",
    "train_text = data[:int(len(data) * 0.9)]\n",
    "val_text = data[int(len(data) * 0.9):]\n",
    "\n",
    "train_tokens = encode_bpe(train_text)\n",
    "val_tokens = encode_bpe(val_text)\n",
    "\n",
    "import torch\n",
    "train_data = torch.tensor(train_tokens)\n",
    "val_data = torch.tensor(val_tokens)\n",
    "\n",
    "print(f\"train has {len(train_data):,} tokens\")\n",
    "print(f\"val has {len(val_data):,} tokens\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "train has 1,478,711 tokens\n",
      "val has 163,429 tokens\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T01:46:56.203564Z",
     "start_time": "2025-03-14T01:46:56.195063Z"
    }
   },
   "source": [
    "# function for getting batches of data\n",
    "def get_batch(split, context_window_size, device, batch_size=32):\n",
    "    \"\"\"\n",
    "    generate a small batch of data of inputs x and targets y\n",
    "\n",
    "    Args:\n",
    "        split: 'train' or 'val'\n",
    "        device: 'cpu' or 'cuda' (should be 'cuda' if available)\n",
    "    \"\"\"\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - context_window_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+context_window_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+context_window_size+1] for i in ix])\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    return x, y\n",
    "\n",
    "# helper function for tracking loss during training\n",
    "# given to you\n",
    "@torch.no_grad()\n",
    "def estimate_loss(model, eval_iters, context_window_size, device, use_focal_loss=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      model: model being evaluated\n",
    "      eval_iters: number of batches to average over\n",
    "      context_window_size: size of the context window\n",
    "      device: 'cpu' or 'cuda' (should be 'cuda' if available)\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for split in ['train', 'val']:\n",
    "        losses_by_type = {\n",
    "            'ce_loss': torch.zeros(eval_iters),\n",
    "        }\n",
    "        if use_focal_loss:\n",
    "            losses_by_type['f_loss'] = torch.zeros(eval_iters)\n",
    "        \n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split, context_window_size, device)\n",
    "            logits, ce_loss, f_loss = model(X, Y)\n",
    "            losses_by_type['ce_loss'][k] = ce_loss.item()\n",
    "            if use_focal_loss:\n",
    "                losses_by_type['f_loss'][k] = f_loss.item()\n",
    "\n",
    "        out[split] = {'ce_loss': losses_by_type['ce_loss'].mean().item()}\n",
    "        if use_focal_loss:\n",
    "            out[split]['f_loss'] = losses_by_type['f_loss'].mean().item()\n",
    "\n",
    "    return out"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T01:53:47.608933Z",
     "start_time": "2025-03-14T01:53:47.596125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size, context_window_size, embed_size=384):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          head_size: int, size of the head embedding dimension (K)\n",
    "          context_window_size: int, number of tokens considered in the past for attention (T)\n",
    "          embed_size: int, size of the token embedding dimension (D)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.head_size = head_size\n",
    "        self.key = nn.Linear(embed_size, head_size, bias=False)\n",
    "        self.query = nn.Linear(embed_size, head_size, bias=False)\n",
    "        self.value = nn.Linear(embed_size, embed_size, bias=False)\n",
    "\n",
    "        # not a param of the model, so registered as a buffer\n",
    "        self.register_buffer('tril', torch.tril(\n",
    "            torch.ones(context_window_size, context_window_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x: (B,T,D) tensor of token embeddings\n",
    "\n",
    "        Returns:\n",
    "          (B,T,D) tensor of attention-weighted token embeddings\n",
    "        \"\"\"\n",
    "        # TODO: your code here\n",
    "        B, T, _ = x.shape\n",
    "        K = self.head_size\n",
    "        key = self.key(x)\n",
    "        query = self.query(x)\n",
    "        value = self.value(x)\n",
    "\n",
    "        attn_scores = query@key.transpose(-2, -1)\n",
    "        causal_mask = self.tril[:T, :T][None, :, :]\n",
    "        attn_scores = attn_scores.masked_fill(causal_mask == 0, float('-inf'))\n",
    "        attn_weights = torch.softmax(attn_scores / (K ** 0.5), dim=-1)\n",
    "        return attn_weights@value\n",
    "\n",
    "class SingleHeadedAttentionLM(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, context_window_size, head_size, embed_size=384):\n",
    "      \"\"\"\n",
    "      Args:\n",
    "        vocab_size: int, size of the vocabulary (V)\n",
    "        context_window_size: int, number of tokens considered in the past for attention (T)\n",
    "        head_size: int, size of the head embedding dimension (K)\n",
    "        embed_size: int, size of the token embedding dimension (D)\n",
    "      \"\"\"\n",
    "      super().__init__()\n",
    "      self.vocab_size = vocab_size\n",
    "      self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
    "      self.position_embedding_table = nn.Embedding(context_window_size, embed_size)\n",
    "      self.context_window_size = context_window_size\n",
    "\n",
    "      # TODO: your code below\n",
    "      self.atten_head = Head(head_size, context_window_size, embed_size)\n",
    "      self.lm_head = nn.Linear(embed_size, vocab_size)\n",
    "\n",
    "    def forward(self, token_ids, targets=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          token_ids: (B, T) token ids that make up the context (batch has size B, each entry\n",
    "                     in the batch has length T)\n",
    "          targets: (B, T) token ids corresponding to the target of each context in token_ids\n",
    "\n",
    "        Returns:\n",
    "          logits: (B, T, V) logits[b,t] gives the length V vector of logits for the next token\n",
    "                   prediction in string b up to t tokens\n",
    "          loss: scalar, negative log likelihood of target given context\n",
    "        \"\"\"\n",
    "        B, T = token_ids.shape # (batch size, length)\n",
    "        tok_emb = self.token_embedding_table(token_ids) # (B,T,D)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,D)\n",
    "        x = tok_emb + pos_emb # (B,T,D)\n",
    "        x = self.atten_head(x) # (B,T,D)\n",
    "        logits = self.lm_head(x) # (B,T,V)\n",
    "\n",
    "        # TODO: your code here\n",
    "        logits = self.lm_head(x)\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, self.vocab_size), targets.view(-1))\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, token_ids, max_new_tokens):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          token_ids: (B, T) tensor of token ids to provide as context\n",
    "          max_new_tokens: int, maximum number of new tokens to generate\n",
    "\n",
    "        Returns:\n",
    "          (B, T+max_new_tokens) tensor of context with new tokens appended\n",
    "        \"\"\"\n",
    "        #TODO\n",
    "        # your code below\n",
    "        B, T = token_ids.shape\n",
    "        new_token_ids = token_ids.clone()\n",
    "        for t in range(max_new_tokens):\n",
    "            logits = self(new_token_ids)\n",
    "            new_token = torch.multinomial(F.softmax(logits[:, -1, :], dim=-1), 1)\n",
    "            new_token_ids = torch.cat([new_token_ids, new_token], dim=1)\n",
    "        return new_token_ids\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, context_window_size, num_heads, head_size, embed_size=384):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            context_window_size: int, number of tokens considered in the past for attention (T)\n",
    "            num_heads: int, number of heads (H)\n",
    "            head_size: int, size of the head embedding dimension\n",
    "            embed_size: int, size of the token embedding dimension\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # TODO, your code below\n",
    "        self.heads = nn.ModuleList([Head(head_size, context_window_size, embed_size) for _ in range(num_heads)])\n",
    "        self.lm_head = nn.Linear(embed_size*num_heads, embed_size)\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO, your code below\n",
    "        B, T, _ = x.shape\n",
    "        head_size = x.shape[-1] // self.num_heads\n",
    "        head_outputs = [head(x) for head in self.heads]\n",
    "        head_outputs = torch.cat(head_outputs, dim=-1)\n",
    "        head_outputs = head_outputs.view(B, T, -1)\n",
    "        return self.lm_head(head_outputs)\n",
    "\n",
    "class MultiHeadedAttentionLM(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, context_window_size, embed_size=384, num_heads=6):\n",
    "      super().__init__()\n",
    "      self.head_size = embed_size // num_heads\n",
    "      self.context_window_size = context_window_size\n",
    "      # TODO: your code below\n",
    "      self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
    "      self.position_embedding_table = nn.Embedding(context_window_size, embed_size)\n",
    "      self.multi_head_attention = MultiHeadAttention(context_window_size, num_heads, self.head_size, embed_size)\n",
    "      self.lm_head = nn.Linear(embed_size, vocab_size)\n",
    "      self.vocab_size = vocab_size\n",
    "\n",
    "    def forward(self, token_ids, targets=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          token_ids: (B, T) token ids that make up the context (batch has size B, each entry in the\n",
    "                     batch has length T)\n",
    "          targets: (B, T) token ids corresponding to the target of each context in token_ids\n",
    "\n",
    "        Returns:\n",
    "          logits: (B, T, V), logits[b,t] gives the length V vector of logits for the next token\n",
    "                  prediction in string b up to t tokens\n",
    "          loss: scalar, negative log likelihood of target given context\n",
    "        \"\"\"\n",
    "        # TODO: your code below\n",
    "        loss = None\n",
    "        B, T = token_ids.shape\n",
    "        tok_emb = self.token_embedding_table(token_ids)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.multi_head_attention(x)\n",
    "        logits = self.lm_head(x)\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, self.vocab_size), targets.view(-1))\n",
    "        return logits, loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, token_ids, max_new_tokens):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          token_ids: (B, T) tensor of token ids to provide as context\n",
    "          max_new_tokens: int, maximum number of new tokens to generate\n",
    "\n",
    "        Returns:\n",
    "          (B, T+max_new_tokens) tensor of context with new tokens appended\n",
    "        \"\"\"\n",
    "        # TODO: your code below\n",
    "        for t in range(max_new_tokens):\n",
    "            if token_ids.shape[1] > self.context_window_size:\n",
    "                token_ids = token_ids[:, -self.context_window_size:]\n",
    "            B, T = token_ids.shape\n",
    "            logits, loss = self.forward(token_ids)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            new_token = torch.multinomial(probs, 1)\n",
    "            token_ids = torch.cat([token_ids, new_token], dim=1)\n",
    "        return token_ids\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity\n",
    "        Given to you, you don't need to write any code here!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embed_size, 4 * embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * embed_size, embed_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\" Transformer block: communication across sequence length, followed by communication across embedding space\n",
    "        Uses multi-headed attention\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, context_window_size, embed_size=384, num_heads=6):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(embed_size)\n",
    "        self.ln2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        # TODO: your code below\n",
    "        self.feed_forward = FeedForward(embed_size)\n",
    "        self.atten_heads = MultiHeadAttention(context_window_size, num_heads, embed_size // num_heads, embed_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.atten_heads(self.ln1(x)) # communication over sequence length\n",
    "        x = x + self.feed_forward(self.ln2(x)) # communication across embedding space\n",
    "        return x\n",
    "\n",
    "def focal_loss(logits, targets, gamma=2.0, alpha=1.0, reduction='mean'):\n",
    "    ce_loss = F.cross_entropy(logits, targets, reduction='none')\n",
    "    pt = torch.exp(-ce_loss)\n",
    "    focal_factor = (1 - pt) ** gamma\n",
    "    loss = alpha * focal_factor * ce_loss\n",
    "\n",
    "    if reduction == 'mean':\n",
    "        return loss.mean()\n",
    "    elif reduction == 'sum':\n",
    "        return loss.sum()\n",
    "    else:\n",
    "        return loss\n",
    "\n",
    "class TransformerLM(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, context_window_size, embed_size=384, num_heads=6, n_layers=6):\n",
    "        \"\"\"\n",
    "          Args:\n",
    "              vocab_size: int, number of tokens in the vocabulary (V)\n",
    "              context_window_size: int, size of the context window (T)\n",
    "              embed_size: int, embedding size (D)\n",
    "              num_heads: int, number of heads (H)\n",
    "              n_layers: int, number of layers (M)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
    "        self.position_embedding_table = nn.Embedding(context_window_size, embed_size)\n",
    "        self.blocks = nn.Sequential(*[\n",
    "            TransformerBlock(vocab_size,\n",
    "                             context_window_size,\n",
    "                             embed_size=embed_size,\n",
    "                             num_heads=num_heads)\n",
    "            for _ in range(n_layers)])\n",
    "\n",
    "        # final layer norm\n",
    "        self.ln_f = nn.LayerNorm(embed_size)\n",
    "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
    "\n",
    "        # good initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, token_ids, targets=None):\n",
    "        B, T = token_ids.shape\n",
    "\n",
    "        # token_ids and targets are both (B, T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(token_ids) # (B, T, D)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, D)\n",
    "        x = tok_emb + pos_emb # (B, T, D)\n",
    "\n",
    "        logits = self.blocks(x)\n",
    "        logits = self.ln_f(logits)\n",
    "        logits = self.lm_head(logits)\n",
    "\n",
    "        if targets is not None:\n",
    "            ce_loss = F.cross_entropy(logits.view(-1, logits.shape[-1]), targets.view(-1))\n",
    "            f_loss = focal_loss(logits.view(-1, logits.shape[-1]), targets.view(-1), gamma=0.5, alpha=1.0)\n",
    "            return logits, ce_loss, f_loss\n",
    "        else:\n",
    "            # Return None for the loss values when targets is None\n",
    "            return logits, None, None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, token_ids, max_new_tokens):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_ids: tensor of integers forming the context, shape (B, T)\n",
    "            max_new_tokens: int, max number of tokens to generate\n",
    "        \"\"\"\n",
    "        # TOOD, your code below\n",
    "        self.eval()\n",
    "        for _ in range(max_new_tokens):\n",
    "            if token_ids.size(1) > CONTEXT_WINDOW_SIZE:\n",
    "                token_ids = token_ids[:, -CONTEXT_WINDOW_SIZE:]\n",
    "            logits, _, _ = self(token_ids)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            token_ids = torch.cat([token_ids, next_token], dim=1)\n",
    "        self.train()\n",
    "        return token_ids\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T01:53:49.741650Z",
     "start_time": "2025-03-14T01:53:49.431676Z"
    }
   },
   "source": [
    "trans = TransformerLM(vocab_size, CONTEXT_WINDOW_SIZE)\n",
    "tlm = trans.to(device)\n",
    "learning_rate = 1e-4\n",
    "# TODO, your code below\n",
    "\n",
    "optimizer = optim.Adam(tlm.parameters(), lr=learning_rate)\n",
    "\n",
    "eval_interval = 200"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T02:19:15.597526Z",
     "start_time": "2025-03-14T01:53:50.028328Z"
    }
   },
   "source": [
    "f_loss_list = []\n",
    "ce_loss_list = []\n",
    "for it in tqdm(range(LARGE_ITERS)):\n",
    "    # Evaluate\n",
    "    if it % eval_interval == 0:\n",
    "        losses = estimate_loss(tlm, EVAL_ITERS, CONTEXT_WINDOW_SIZE, device, use_focal_loss=True)\n",
    "        print(f\"step {it}: train loss {losses['train']}, val loss {losses['val']}\")\n",
    "    \n",
    "    # Forward/backward/update\n",
    "    xb, yb = get_batch('train', CONTEXT_WINDOW_SIZE, device, batch_size = 64)\n",
    "    logits, ce_loss, f_loss = tlm(xb, yb)\n",
    "    optimizer.zero_grad()\n",
    "    ce_loss.backward()\n",
    "    optimizer.step()\n",
    "    f_loss_list.append(f_loss.item())\n",
    "    ce_loss_list.append(ce_loss.item())\n",
    "\n",
    "print(\"final CE training loss =\", ce_loss_list[-1])\n",
    "print(\"final F training loss =\", f_loss_list[-1])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss {'ce_loss': 7.683197021484375, 'f_loss': 7.681325912475586}, val loss {'ce_loss': 7.689102649688721, 'f_loss': 7.6872406005859375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 200/2000 [02:32<19:29,  1.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 200: train loss {'ce_loss': 5.125899791717529, 'f_loss': 5.089196681976318}, val loss {'ce_loss': 5.195276260375977, 'f_loss': 5.159502983093262}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 400/2000 [05:06<17:29,  1.53it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 400: train loss {'ce_loss': 4.717345714569092, 'f_loss': 4.674659252166748}, val loss {'ce_loss': 4.828733444213867, 'f_loss': 4.787356853485107}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 600/2000 [07:42<15:37,  1.49it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 600: train loss {'ce_loss': 4.387252330780029, 'f_loss': 4.340536594390869}, val loss {'ce_loss': 4.555135250091553, 'f_loss': 4.510833263397217}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 800/2000 [10:16<12:59,  1.54it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 800: train loss {'ce_loss': 4.175746917724609, 'f_loss': 4.1251540184021}, val loss {'ce_loss': 4.3836350440979, 'f_loss': 4.337018013000488}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1000/2000 [12:48<10:50,  1.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000: train loss {'ce_loss': 3.9852514266967773, 'f_loss': 3.929575204849243}, val loss {'ce_loss': 4.254449367523193, 'f_loss': 4.204405307769775}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1200/2000 [15:19<08:37,  1.55it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1200: train loss {'ce_loss': 3.8223073482513428, 'f_loss': 3.7623581886291504}, val loss {'ce_loss': 4.1174821853637695, 'f_loss': 4.063620567321777}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1400/2000 [17:50<06:29,  1.54it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1400: train loss {'ce_loss': 3.696096897125244, 'f_loss': 3.632251024246216}, val loss {'ce_loss': 4.040282726287842, 'f_loss': 3.983555316925049}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1600/2000 [20:22<04:19,  1.54it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1600: train loss {'ce_loss': 3.6006851196289062, 'f_loss': 3.534271478652954}, val loss {'ce_loss': 3.980137586593628, 'f_loss': 3.9208076000213623}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 1800/2000 [22:53<02:09,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1800: train loss {'ce_loss': 3.5026135444641113, 'f_loss': 3.435037851333618}, val loss {'ce_loss': 3.917358636856079, 'f_loss': 3.8574182987213135}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [25:25<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final CE training loss = 3.46881365776062\n",
      "final F training loss = 3.3998193740844727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T02:22:47.874576Z",
     "start_time": "2025-03-14T02:22:25.643746Z"
    }
   },
   "source": [
    "estimate_loss(tlm, EVAL_ITERS, CONTEXT_WINDOW_SIZE, device, use_focal_loss=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'ce_loss': 3.4172675609588623, 'f_loss': 3.3467981815338135},\n",
       " 'val': {'ce_loss': 3.878727912902832, 'f_loss': 3.8162343502044678}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T01:53:00.689616Z",
     "start_time": "2025-03-14T01:48:26.271266Z"
    }
   },
   "source": [
    "f_loss_list = []\n",
    "ce_loss_list = []\n",
    "for it in tqdm(range(LARGE_ITERS)):\n",
    "    # Evaluate\n",
    "    if it % eval_interval == 0:\n",
    "        losses = estimate_loss(tlm, EVAL_ITERS, CONTEXT_WINDOW_SIZE, device, use_focal_loss=True)\n",
    "        print(f\"step {it}: train loss {losses['train']}, val loss {losses['val']}\")\n",
    "    \n",
    "    # Forward/backward/update\n",
    "    xb, yb = get_batch('train', CONTEXT_WINDOW_SIZE, device, batch_size = 64)\n",
    "    logits, ce_loss, f_loss = tlm(xb, yb)\n",
    "    optimizer.zero_grad()\n",
    "    f_loss.backward()\n",
    "    optimizer.step()\n",
    "    f_loss_list.append(f_loss.item())\n",
    "    ce_loss_list.append(ce_loss.item())\n",
    "\n",
    "print(\"final CE training loss =\", ce_loss_list[-1])\n",
    "print(\"final F training loss =\", f_loss_list[-1])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss {'ce_loss': 7.650057792663574, 'f_loss': 7.648144721984863}, val loss {'ce_loss': 7.6523051261901855, 'f_loss': 7.650395393371582}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 200/2000 [02:33<19:30,  1.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 200: train loss {'ce_loss': 5.111303329467773, 'f_loss': 5.072350025177002}, val loss {'ce_loss': 5.183755397796631, 'f_loss': 5.145900726318359}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 350/2000 [04:34<21:33,  1.28it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m logits, ce_loss, f_loss \u001B[38;5;241m=\u001B[39m tlm(xb, yb)\n\u001B[1;32m     12\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 13\u001B[0m \u001B[43mf_loss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     15\u001B[0m f_loss_list\u001B[38;5;241m.\u001B[39mappend(f_loss\u001B[38;5;241m.\u001B[39mitem())\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py:626\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    616\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    617\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    618\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    619\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    624\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    625\u001B[0m     )\n\u001B[0;32m--> 626\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    627\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    628\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    821\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    822\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    825\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    826\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T22:32:19.277965Z",
     "start_time": "2025-03-13T22:31:56.815984Z"
    }
   },
   "source": [
    "start_context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "uncond_gen = (tlm.generate(start_context, max_new_tokens=CONTEXT_WINDOW_SIZE)[0].tolist())"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T22:32:22.417097Z",
     "start_time": "2025-03-13T22:32:22.411327Z"
    }
   },
   "source": [
    "print(decode_bpe(uncond_gen))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "force\n",
      "Prangery-nobed, and mine own; and--\n",
      "\n",
      "KING LEAR:\n",
      "Good lad defence, infinite; one; lay'st thou down\n",
      "Thy sack in the angry, and neither a slail better;\n",
      "And throw him out on this, or do you rob\n",
      "To do thee spies, to whiles, seeming changed,\n",
      "And with his oured tongues, that hastys thress\n",
      "May make her big and deliver'd easy.\n",
      "Hath not this done well? I call here open,\n",
      "O'er-adbeyGrappaigo: lay away\n",
      "The ancient of things to do each one: ho!\n",
      "\n",
      "REHAN:\n",
      "'Tis so, fellow. 'tis not with us: you are so.\n",
      "\n",
      "EARL OF DANGOR PANCESTER:\n",
      "You are with me, sirs: go you to blush\n",
      "The rein: we'll kill you.\n",
      "\n",
      "HOTSPUR:\n",
      "\n",
      "Just Romeo! wilt thou go, let me be the seashards\n",
      "And pay\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T22:32:44.561521Z",
     "start_time": "2025-03-13T22:32:44.549988Z"
    }
   },
   "source": [
    "xb, yb = get_batch(split='train', context_window_size=CONTEXT_WINDOW_SIZE, device=device)"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T22:32:46.791986Z",
     "start_time": "2025-03-13T22:32:46.237535Z"
    }
   },
   "source": [
    "decode_bpe(tlm.generate(xb[0:1], max_new_tokens=10).tolist()[0])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? As Caesar loved me, I weep for him;\\nas he was fortunate, I rejoice at it; as he was\\nvaliant, I honour him: but, as he was ambitious, I\\nslew him. There is tears for his love; joy for his\\nfortune; honour for his valour; and death for his\\nambition. Who is here so base that would be a\\nbondman? If any, speak; for him have I offended.\\nWho is here so rude that would not be a Roman? If\\nany, speak; for him have I offended. Who is here so\\nvile that will not love his country? If any, speak;\\nfor him have I offended. I pause for a reply.\\n\\nAll:\\nNone, Brutus, none.\\n\\nBRUTUS:\\nThen none have I offended. I have done no more to\\nCaesar than you shall do to Brutus. The question of\\nhis death is enrolled in the Capitol; his gloss is\\nwith the present temple and'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## M-Loss"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T00:11:09.022408Z",
     "start_time": "2025-03-14T00:11:09.016532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def m_loss(logits, targets, alpha=1.0, epsilon=1e-5, clamp_min=0.05, clamp_max=0.95, reduction='mean'):\n",
    "    \"\"\"\n",
    "    Improved M Loss function with better numerical stability for language modeling.\n",
    "\n",
    "    Args:\n",
    "        logits: Tensor of shape (batch_size * seq_len, vocab_size)\n",
    "        targets: Tensor of shape (batch_size * seq_len)\n",
    "        alpha: Weighting factor\n",
    "        epsilon: Small constant to prevent division by zero\n",
    "        clamp_min: Minimum probability value to prevent extreme values\n",
    "        clamp_max: Maximum probability value to prevent extreme values\n",
    "        reduction: 'mean' or 'sum'\n",
    "\n",
    "    Returns:\n",
    "        Loss value\n",
    "    \"\"\"\n",
    "    # Convert targets to one-hot encoding\n",
    "    vocab_size = logits.size(-1)\n",
    "    one_hot = F.one_hot(targets, num_classes=vocab_size).float()\n",
    "\n",
    "    # Get predicted probabilities with softmax and clamp to avoid extreme values\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    probs = torch.clamp(probs, min=clamp_min, max=clamp_max)\n",
    "\n",
    "    # Calculate stabilized M loss\n",
    "    # Instead of direct division, use log-space operations\n",
    "    log_probs = torch.log(probs + epsilon)\n",
    "    log_inv_probs = torch.log(1 - probs + epsilon)\n",
    "\n",
    "    # Calculate components in log space to avoid numerical issues\n",
    "    pos_term = one_hot * torch.exp(torch.clamp(-log_probs, max=10))\n",
    "    neg_term = (1 - one_hot) * torch.exp(torch.clamp(-log_inv_probs, max=10))\n",
    "\n",
    "    # Combine terms with a smooth transition\n",
    "    m_loss_values = pos_term + neg_term - 1\n",
    "\n",
    "    # Apply alpha weighting and reduce\n",
    "    loss = alpha * m_loss_values.sum(dim=-1)\n",
    "\n",
    "    if reduction == 'mean':\n",
    "        return loss.mean()\n",
    "    elif reduction == 'sum':\n",
    "        return loss.sum()\n",
    "    else:\n",
    "        return loss"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T00:20:32.226237Z",
     "start_time": "2025-03-14T00:20:32.155206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerLM_losstest(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, context_window_size, embed_size=384, num_heads=6, n_layers=6):\n",
    "        \"\"\"\n",
    "          Args:\n",
    "              vocab_size: int, number of tokens in the vocabulary (V)\n",
    "              context_window_size: int, size of the context window (T)\n",
    "              embed_size: int, embedding size (D)\n",
    "              num_heads: int, number of heads (H)\n",
    "              n_layers: int, number of layers (M)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
    "        self.position_embedding_table = nn.Embedding(context_window_size, embed_size)\n",
    "        self.blocks = nn.Sequential(*[\n",
    "            TransformerBlock(vocab_size,\n",
    "                             context_window_size,\n",
    "                             embed_size=embed_size,\n",
    "                             num_heads=num_heads)\n",
    "            for _ in range(n_layers)])\n",
    "\n",
    "        # final layer norm\n",
    "        self.ln_f = nn.LayerNorm(embed_size)\n",
    "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
    "\n",
    "        # good initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, token_ids, targets=None):\n",
    "        B, T = token_ids.shape\n",
    "\n",
    "        # token_ids and targets are both (B, T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(token_ids) # (B, T, D)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, D)\n",
    "        x = tok_emb + pos_emb # (B, T, D)\n",
    "\n",
    "        logits = self.blocks(x)\n",
    "        logits = self.ln_f(logits)\n",
    "        logits = self.lm_head(logits)\n",
    "\n",
    "        if targets is not None:\n",
    "            ce_loss = F.cross_entropy(logits.view(-1, logits.shape[-1]), targets.view(-1))\n",
    "            f_loss = focal_loss(logits.view(-1, logits.shape[-1]), targets.view(-1), gamma=0.5, alpha=1.0)\n",
    "            m_loss_val = m_loss(logits.view(-1, logits.shape[-1]), targets.view(-1))\n",
    "            return logits, ce_loss, f_loss, m_loss_val\n",
    "        else:\n",
    "            # Return None for loss values during inference\n",
    "            return logits, None, None, None\n",
    "\n",
    "   # 3. Update the generate method to handle the new return values\n",
    "    @torch.no_grad()\n",
    "    def generate(self, token_ids, max_new_tokens):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_ids: tensor of integers forming the context, shape (B, T)\n",
    "            max_new_tokens: int, max number of tokens to generate\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        for _ in range(max_new_tokens):\n",
    "            if token_ids.size(1) > CONTEXT_WINDOW_SIZE:\n",
    "                token_ids = token_ids[:, -CONTEXT_WINDOW_SIZE:]\n",
    "            logits, _, _, _ = self(token_ids)  # Unpack four values now\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            token_ids = torch.cat([token_ids, next_token], dim=1)\n",
    "        self.train()\n",
    "        return token_ids\n"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T00:20:33.591546Z",
     "start_time": "2025-03-14T00:20:33.587145Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 46,
   "source": [
    "# 4. Update the estimate_loss function to handle M Loss\n",
    "@torch.no_grad()\n",
    "def estimate_losstest(model, eval_iters, context_window_size, device, use_focal_loss=False, use_m_loss=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      model: model being evaluated\n",
    "      eval_iters: number of batches to average over\n",
    "      context_window_size: size of the context window\n",
    "      device: 'cpu' or 'cuda' (should be 'cuda' if available)\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for split in ['train', 'val']:\n",
    "        losses_by_type = {\n",
    "            'ce_loss': torch.zeros(eval_iters),\n",
    "        }\n",
    "        if use_focal_loss:\n",
    "            losses_by_type['f_loss'] = torch.zeros(eval_iters)\n",
    "        if use_m_loss:\n",
    "            losses_by_type['m_loss'] = torch.zeros(eval_iters)\n",
    "\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split, context_window_size, device)\n",
    "            logits, ce_loss, f_loss, m_loss_val = model(X, Y)\n",
    "            losses_by_type['ce_loss'][k] = ce_loss.item()\n",
    "            if use_focal_loss:\n",
    "                losses_by_type['f_loss'][k] = f_loss.item()\n",
    "            if use_m_loss:\n",
    "                losses_by_type['m_loss'][k] = m_loss_val.item()\n",
    "\n",
    "        out[split] = {'ce_loss': losses_by_type['ce_loss'].mean().item()}\n",
    "        if use_focal_loss:\n",
    "            out[split]['f_loss'] = losses_by_type['f_loss'].mean().item()\n",
    "        if use_m_loss:\n",
    "            out[split]['m_loss'] = losses_by_type['m_loss'].mean().item()\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T00:20:35.544335Z",
     "start_time": "2025-03-14T00:20:34.469627Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 47,
   "source": [
    "trans_test = TransformerLM_losstest(vocab_size, CONTEXT_WINDOW_SIZE)\n",
    "tlm_test = trans_test.to(device)\n",
    "learning_rate = 1e-4\n",
    "# TODO, your code below\n",
    "\n",
    "optimizer = optim.Adam(tlm_test.parameters(), lr=learning_rate)\n",
    "\n",
    "eval_interval = 200"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T00:22:53.035246Z",
     "start_time": "2025-03-14T00:22:19.003976Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss {'ce_loss': 2.663043260574341, 'f_loss': 2.5754470825195312}, val loss {'ce_loss': 3.8241536617279053, 'f_loss': 3.7587201595306396}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2000 [00:33<1:10:14,  2.12s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[51], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m logits, ce_loss, f_loss \u001B[38;5;241m=\u001B[39m tlm(xb, yb)\n\u001B[1;32m     13\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 14\u001B[0m \u001B[43mf_loss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Use M loss for optimization\u001B[39;00m\n\u001B[1;32m     15\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     16\u001B[0m ce_loss_list\u001B[38;5;241m.\u001B[39mappend(ce_loss\u001B[38;5;241m.\u001B[39mitem())\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py:626\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    616\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    617\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    618\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    619\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    624\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    625\u001B[0m     )\n\u001B[0;32m--> 626\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    627\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    628\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    821\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    822\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    825\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    826\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 51,
   "source": [
    "# 5. Training loop with M Loss\n",
    "m_loss_list = []\n",
    "ce_loss_list = []\n",
    "for it in tqdm(range(LARGE_ITERS)):\n",
    "    # Evaluate\n",
    "    if it % eval_interval == 0:\n",
    "        losses = estimate_loss(tlm, EVAL_ITERS, CONTEXT_WINDOW_SIZE, device, use_focal_loss=True)\n",
    "        print(f\"step {it}: train loss {losses['train']}, val loss {losses['val']}\")\n",
    "\n",
    "    # Forward/backward/update\n",
    "    xb, yb = get_batch('train', CONTEXT_WINDOW_SIZE, device, batch_size=64)\n",
    "    logits, ce_loss, f_loss = tlm(xb, yb)\n",
    "    optimizer.zero_grad()\n",
    "    f_loss.backward()  # Use M loss for optimization\n",
    "    optimizer.step()\n",
    "    ce_loss_list.append(ce_loss.item())\n",
    "\n",
    "print(\"final CE training loss =\", ce_loss_list[-1])\n",
    "print(\"final M training loss =\", m_loss_list[-1])\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T00:25:25.340534Z",
     "start_time": "2025-03-14T00:25:25.252525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_loss_comparison(ce_losses, focal_losses):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(ce_losses, label='Cross-Entropy Loss')\n",
    "    plt.plot(focal_losses, label='Focal Loss')\n",
    "    plt.title('Training Loss Comparison')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Calculate average loss over last 100 iterations\n",
    "    avg_ce = sum(ce_losses[-100:]) / 100\n",
    "    avg_focal = sum(focal_losses[-100:]) / 100\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(['CE Loss', 'Focal Loss'], [avg_ce, avg_focal])\n",
    "    plt.title('Average Loss (Last 100 Iterations)')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call this after training with all three loss functions\n",
    "plot_loss_comparison(ce_loss_list, f_loss_list)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
